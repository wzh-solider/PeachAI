{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#os ： OS模块提供了非常丰富的方法用来处理文件和目录。\n",
    "#sys：sys模块提供了一系列有关Python运行环境的变量和函数。\n",
    "#shutil:用于文件拷贝的模块 \n",
    "#numpy：numpy 是 Python 语言的一个扩展程序库，支持大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。\n",
    "#random：Python中的random模块用于生成随机数。\n",
    "#paddle.vision.datasets：该模块包含数据加载的相关函数，比如可以用来加载常用的数据集等，如mnist。\n",
    "#paddle.vision.transforms:该模块包含对图像进行转换的函数，比如把HWC格式的图片，转变成CHW模式的输入张量。也包含飞桨框架对于图像预处理的方式，可以快速完成常见的图像预处理，如调整色调、对比度，图像大小等；\n",
    "#paddle.io.Dataset:高模块包含了飞桨框架数据加载方式，可以“一键”完成数据的批加载与异步加载。\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import paddle\n",
    "import random\n",
    "from paddle.io import Dataset, DataLoader\n",
    "from paddle.vision.datasets import DatasetFolder, ImageFolder\n",
    "from paddle.vision import transforms as T"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:45:32.505664Z",
     "start_time": "2024-04-14T17:45:32.502398Z"
    }
   },
   "id": "340e37c3d4c0e54d",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# '''\n",
    "# 参数配置：\n",
    "# 'train_data_dir'是提供的经增强后的原始训练集；\n",
    "# 'test_image_dir'是提供的原始测试集；\n",
    "# 'train_image_dir'和'eval_image_dir'是由原始训练集经拆分后生成的实际训练集和验证集\n",
    "# 'train_list_dir'和'test_list_dir'是生成的txt文件路径\n",
    "# 'saved_model' 存放训练结果的文件夹\n",
    "# '''\n",
    "train_parameters = {\n",
    "    'train_image_dir': './data/splitted_training_data/train_images',\n",
    "    'eval_image_dir': './data/splitted_training_data/eval_images',\n",
    "    'test_image_dir': './data/enhancement_data/test',\n",
    "    'train_data_dir': './data/enhancement_data/train',\n",
    "    'train_list_dir': './data/enhancement_data/train.txt',\n",
    "    'test_list_dir': './data/enhancement_data/test.txt',\n",
    "    'saved_model': './saved_model/'\n",
    "}\n",
    "\n",
    "#数据集的4个类别标签\n",
    "labels = ['R0', 'B1', 'M2', 'S3']\n",
    "labels.sort()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:45:32.552781Z",
     "start_time": "2024-04-14T17:45:32.548153Z"
    }
   },
   "id": "b4c6c18e4a0c066d",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#准备生成训练集文件名、标签名的txt文件\n",
    "write_file_name = train_parameters['train_list_dir']\n",
    "\n",
    "#以写方式打开write_file_name文件\n",
    "with open(write_file_name, \"w\") as write_file:\n",
    "    #针对不同的分类标签分别录入\n",
    "    for label in labels:\n",
    "        #建立空列表，用于保存图片名\n",
    "        file_list = []\n",
    "        #用于找到该标签路径下的所有图片.\n",
    "        train_txt_dir = train_parameters['train_data_dir'] + '/' + label + '/'\n",
    "\n",
    "        for file_name in os.listdir(train_txt_dir):\n",
    "            dir_name = label\n",
    "            temp_line = dir_name + '/' + file_name + '\\t' + label + '\\n'  # 例如：\"B1/101.png\tB1\"\n",
    "            write_file.write(temp_line)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:45:32.596130Z",
     "start_time": "2024-04-14T17:45:32.584965Z"
    }
   },
   "id": "7a22f6855f6393e6",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#准备生成测试集文件名、标签名的txt文件\n",
    "write_file_name = train_parameters['test_list_dir']\n",
    "\n",
    "#以写方式打开write_file_name文件\n",
    "with open(write_file_name, \"w\") as write_file:\n",
    "    #针对不同的分类标签分别录入\n",
    "    for label in labels:\n",
    "        #建立空列表，用于保存图片名\n",
    "        file_list = []\n",
    "        #用于找到该标签路径下的所有图片.\n",
    "        train_txt_dir = train_parameters['test_image_dir'] + '/' + label + '/'\n",
    "\n",
    "        for file_name in os.listdir(train_txt_dir):\n",
    "            dir_name = label\n",
    "            temp_line = dir_name + '/' + file_name + '\\t' + label + '\\n'  # 例如：\"B1/101.png\tB1\"\n",
    "            write_file.write(temp_line)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:45:32.604046Z",
     "start_time": "2024-04-14T17:45:32.599282Z"
    }
   },
   "id": "824e3679d30e2822",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#判断splitted_training_data文件夹是否存在，如果不存在就新建一个\n",
    "if not os.path.exists('data/splitted_training_data'):\n",
    "    os.makedirs('data/splitted_training_data')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:45:32.608727Z",
     "start_time": "2024-04-14T17:45:32.605105Z"
    }
   },
   "id": "4ae867d3577c06b4",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating training and eval images\n",
      "划分训练集和验证集完成！\n"
     ]
    }
   ],
   "source": [
    "#定义一个函数，来拆分训练集、验证集\n",
    "def create_train_eval():\n",
    "    '''\n",
    "    划分训练集和验证集\n",
    "    '''\n",
    "    train_dir = train_parameters['train_image_dir']\n",
    "    eval_dir = train_parameters['eval_image_dir']\n",
    "    train_list_path = train_parameters['train_list_dir']\n",
    "    train_data_dir = train_parameters['train_data_dir']\n",
    "\n",
    "    print('creating training and eval images')\n",
    "    #如果文件夹不存在，建立相应的文件夹\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.mkdir(train_dir)\n",
    "    if not os.path.exists(eval_dir):\n",
    "        os.mkdir(eval_dir)\n",
    "\n",
    "        #打开txt文件，分割数据\n",
    "    file_name = train_list_path\n",
    "    f = open(file_name, 'r')\n",
    "    #按行读取数据\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        #将每行数据按照空格分割成2部分，并取第一部分的路径名和图像文件名，例如:R0/1.png\n",
    "        img_path = lines[i].split('\\t')[0]\n",
    "        #取第二部分的标签，例如:R0\n",
    "        class_label = lines[i].split('\\t')[1].strip('\\n')\n",
    "        # 每8张图片取一个做验证数据,其他用于训练\n",
    "        if i % 8 == 0:\n",
    "            #把目录和文件名合成一个路径\n",
    "            eval_target_dir = os.path.join(eval_dir, class_label)\n",
    "            #将总的文件路径与当前图像的文件名合到一起，实际就是得到训练集图像所在的文件夹下的图像名   \n",
    "            eval_img_path = os.path.join(train_data_dir, img_path)\n",
    "            if not os.path.exists(eval_target_dir):\n",
    "                os.mkdir(eval_target_dir)\n",
    "                #将图片复制到验证集指定标签的文件夹下      \n",
    "            shutil.copy(eval_img_path, eval_target_dir)\n",
    "        else:\n",
    "            train_target_dir = os.path.join(train_dir, class_label)\n",
    "            train_img_path = os.path.join(train_data_dir, img_path)\n",
    "            if not os.path.exists(train_target_dir):\n",
    "                os.mkdir(train_target_dir)\n",
    "            shutil.copy(train_img_path, train_target_dir)\n",
    "    print('划分训练集和验证集完成！')\n",
    "\n",
    "# 制作数据集，如果已经做好了，就请将代码注释掉\n",
    "# create_train_eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:45:40.275077Z",
     "start_time": "2024-04-14T17:45:32.629039Z"
    }
   },
   "id": "7322e039ad424623",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class PeachDataset(Dataset):\n",
    "    \"\"\"\n",
    "    步骤一：继承paddle.io.Dataset类\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mode='train'):\n",
    "        \"\"\"\n",
    "        步骤二：实现构造函数，定义数据读取方式，划分训练、验证和测试数据集\n",
    "        \"\"\"\n",
    "        super(PeachDataset, self).__init__()\n",
    "        train_image_dir = train_parameters['train_image_dir']  #训练集的路径\n",
    "        eval_image_dir = train_parameters['eval_image_dir']\n",
    "        test_image_dir = train_parameters['test_image_dir']\n",
    "\n",
    "        '''         '''\n",
    "        #transform数据增强函数，这里仅对图片的打开方式进行了转换            \n",
    "        #这里用Transpose()将图片的打开方式(宽, 高, 通道数)更改为PaddlePaddle读取的方式是(通道数, 宽, 高)\n",
    "        mean = [127.5, 127.5, 127.5]  # 归一化，均值\n",
    "        std = [127.5, 127.5, 127.5]  # 归一化，标注差 \n",
    "        transform_train = T.Compose([T.ColorJitter(0.4, 0.4, 0.4, 0.4)\n",
    "                                        , T.Resize(size=(224, 224))\n",
    "                                        , T.Transpose()\n",
    "                                        , T.Normalize(mean, std)\n",
    "                                     ])\n",
    "        transform_eval = T.Compose([T.Resize(size=(224, 224))\n",
    "                                       , T.Transpose()\n",
    "                                       , T.Normalize(mean, std)\n",
    "                                    ])\n",
    "        transform_test = T.Compose([T.Resize(size=(224, 224))\n",
    "                                       , T.Transpose()\n",
    "                                       , T.Normalize(mean, std)\n",
    "                                    ])\n",
    "\n",
    "        '''         \n",
    "        # 参考API：https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/Overview_cn.html#about-transforms\n",
    "        #这里用Transpose()将图片的打开方式(宽, 高, 通道数)更改为PaddlePaddle读取的方式是(通道数, 宽, 高)\n",
    "        # ColorJitter 随机调整图像的亮度，对比度，饱和度和色调。\n",
    "        # hflip 对输入图像进行水平翻转。        \n",
    "        # Normalize 归一化。mean = [127.5, 127.5, 127.5]，std = [127.5, 127.5, 127.5]\n",
    "        # RandomHorizontalFlip 基于概率来执行图片的水平翻转。\n",
    "        # RandomVerticalFlip 基于概率来执行图片的垂直翻转。\n",
    "        mean = [127.5, 127.5, 127.5] # 归一化，均值\n",
    "        std = [127.5, 127.5, 127.5] # 归一化，标注差 \n",
    "        transform_train = T.Compose([T.Resize(size=(224,224)), \n",
    "                                     T.Transpose(),                                \n",
    "                                     T.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "                                     T.RandomHorizontalFlip(prob=0.5,),\n",
    "                                     T.RandomVerticalFlip(prob=0.5,),\n",
    "                                     T.Normalize(mean, std)])\n",
    "        transform_eval = T.Compose([T.Resize(size=(224,224)), T.Transpose()])\n",
    "        transform_test = T.Compose([T.Resize(size=(224,224)), T.Transpose()])\n",
    "        '''\n",
    "\n",
    "        #飞桨推荐使用 paddle.io.DataLoader 完成数据的加载，生成一个可以加载数据的迭代器\n",
    "        # 参考API:https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/io/DataLoader_cn.html#cn-api-fluid-io-dataloader\n",
    "        #加载训练集，train_data_folder 是一个迭代器\n",
    "        # 参考API：https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/datasets/DatasetFolder_cn.html#datasetfolder\n",
    "        train_data_folder = DatasetFolder(train_image_dir, transform=transform_train)\n",
    "        #加载验证集，eval_data_folder 是一个迭代器\n",
    "        eval_data_folder = DatasetFolder(eval_image_dir, transform=transform_eval)\n",
    "        #加载测试集，test_data_folder 是一个迭代器\n",
    "        test_data_folder = DatasetFolder(test_image_dir, transform=transform_test)\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "            self.data = train_data_folder\n",
    "        elif self.mode == 'eval':\n",
    "            self.data = eval_data_folder\n",
    "        elif self.mode == 'test':\n",
    "            self.data = test_data_folder\n",
    "\n",
    "    # 每次迭代时返回数据和对应的标签\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        步骤三：实现__getitem__方法，定义指定index时如何获取数据，并返回单条数据（训练数据，对应的标签）\n",
    "        \"\"\"\n",
    "        data = np.array(self.data[index][0]).astype('float32')\n",
    "\n",
    "        label = np.array([self.data[index][1]]).astype('int64')\n",
    "\n",
    "        return data, label\n",
    "\n",
    "    # 返回整个数据集的总数\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        步骤四：实现__len__方法，返回数据集总数目\n",
    "        \"\"\"\n",
    "        return len(self.data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:45:40.283686Z",
     "start_time": "2024-04-14T17:45:40.276087Z"
    }
   },
   "id": "c458ab62832e2857",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#用自定义的PeachDataset类，加载自己的数据集\n",
    "train_dataset = PeachDataset(mode='train')\n",
    "val_dataset = PeachDataset(mode='eval')\n",
    "test_dataset = PeachDataset(mode='test')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:45:40.362153Z",
     "start_time": "2024-04-14T17:45:40.284891Z"
    }
   },
   "id": "8276f74e1dd0f1b8",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opencv 版本号为：4.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\io\\reader.py:429: UserWarning: DataLoader with multi-process mode is not supported on MacOs and Windows currently. Please use signle-process mode with num_workers = 0 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# DataLoader 示例代码\n",
    "\n",
    "# 加载库\n",
    "import cv2 as cv  #使用 OpenCV\n",
    "\n",
    "print(\"opencv 版本号为：\" + cv.__version__)  #查看版本号\n",
    "# 事实上在使用 OpenCV之前应该安装该类库，但是由于使用了 AI-Studio，所以系统已经替开发者预先安装好了： opencv-python 4.1.1.26       \n",
    "from matplotlib import pyplot as plt  #在该页面画图\n",
    "%matplotlib inline \n",
    "\n",
    "# 构造一个 DataLoader\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=2,\n",
    "                         shuffle=True,\n",
    "                         drop_last=True,\n",
    "                         num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:45:40.725264Z",
     "start_time": "2024-04-14T17:45:40.364355Z"
    }
   },
   "id": "37945b6eb1cae757",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini_batch 的类型为：<class 'list'>\n",
      "mini_batch 的大小为：2\n",
      "(3, 224, 224)\n",
      "(3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "# 使用 DataLoader 来遍历数据集\n",
    "for mini_batch in test_loader:  # 从 DataLoader 中获取 mini_batch \n",
    "    print(\"mini_batch 的类型为：\" + str(type(mini_batch)))\n",
    "    pic_list = mini_batch[0]  #图片数据\n",
    "    label_list = mini_batch[1]  #标记\n",
    "    print(\"mini_batch 的大小为：\" + str(len(pic_list)))\n",
    "\n",
    "    # 将图片显示转化为 numpy 格式，并且将内部的数字设置为 整数类型\n",
    "    pic_1 = pic_list[0]\n",
    "    pic_2 = pic_list[1]\n",
    "    arr1 = np.asarray(pic_1, dtype=np.float64)\n",
    "    print(arr1.shape)\n",
    "    arr2 = np.asarray(pic_2, dtype=np.float64)\n",
    "    print(arr2.shape)\n",
    "\n",
    "    break  #由于是示例，所以仅拿出第一个 mini_batch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:45:40.767316Z",
     "start_time": "2024-04-14T17:45:40.725264Z"
    }
   },
   "id": "75353e4e8724dc25",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 把获取到的图片数据展示出来\n",
    "# arr1 = arr1 / 255 # 把每一个像素都变到 0-1 之间\n",
    "# r = arr1[0]\n",
    "# g = arr1[1]\n",
    "# b = arr1[2]\n",
    "# img = cv.merge([r, g, b])\n",
    "# \n",
    "# plt.imshow(img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:45:40.772580Z",
     "start_time": "2024-04-14T17:45:40.768405Z"
    }
   },
   "id": "95ae01f36911f7db",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:2084: UserWarning: Skip loading for fc.weight. fc.weight receives a shape [512, 1000], but the expected shape is [512, 4].\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "E:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:2084: UserWarning: Skip loading for fc.bias. fc.bias receives a shape [1000], but the expected shape is [4].\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n"
     ]
    }
   ],
   "source": [
    "# 使用内置的模型,这边可以选择多种不同网络，这里选了resnet50网络\n",
    "#pretrained (bool，可选) - 是否加载在imagenet数据集上的预训练权重\n",
    "model = paddle.vision.models.resnet18(pretrained=True, num_classes=4)\n",
    "\n",
    "#尝试不同的网络结构：MobileNetV2\n",
    "# MobileNetV2参考文档：https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/models/MobileNetV2_cn.html\n",
    "# model = paddle.vision.models.mobilenet_v2(pretrained=True, num_classes=4)    \n",
    "\n",
    "#使用paddle.Model完成模型的封装，将网络结构组合成一个可快速使用高层API进行训练和预测的类。\n",
    "model = paddle.Model(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:45:41.783074Z",
     "start_time": "2024-04-14T17:45:40.773641Z"
    }
   },
   "id": "1e273f2031247d08",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "   Layer (type)         Input Shape          Output Shape         Param #    \n",
      "===============================================================================\n",
      "     Conv2D-1        [[1, 3, 224, 224]]   [1, 64, 112, 112]        9,408     \n",
      "   BatchNorm2D-1    [[1, 64, 112, 112]]   [1, 64, 112, 112]         256      \n",
      "      ReLU-1        [[1, 64, 112, 112]]   [1, 64, 112, 112]          0       \n",
      "    MaxPool2D-1     [[1, 64, 112, 112]]    [1, 64, 56, 56]           0       \n",
      "     Conv2D-2        [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \n",
      "   BatchNorm2D-2     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \n",
      "      ReLU-2         [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "     Conv2D-3        [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \n",
      "   BatchNorm2D-3     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \n",
      "   BasicBlock-1      [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "     Conv2D-4        [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \n",
      "   BatchNorm2D-4     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \n",
      "      ReLU-3         [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "     Conv2D-5        [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \n",
      "   BatchNorm2D-5     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \n",
      "   BasicBlock-2      [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "     Conv2D-7        [[1, 64, 56, 56]]     [1, 128, 28, 28]       73,728     \n",
      "   BatchNorm2D-7     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "      ReLU-4         [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "     Conv2D-8        [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456    \n",
      "   BatchNorm2D-8     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "     Conv2D-6        [[1, 64, 56, 56]]     [1, 128, 28, 28]        8,192     \n",
      "   BatchNorm2D-6     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "   BasicBlock-3      [[1, 64, 56, 56]]     [1, 128, 28, 28]          0       \n",
      "     Conv2D-9        [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456    \n",
      "   BatchNorm2D-9     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "      ReLU-5         [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "     Conv2D-10       [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456    \n",
      "  BatchNorm2D-10     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "   BasicBlock-4      [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "     Conv2D-12       [[1, 128, 28, 28]]    [1, 256, 14, 14]       294,912    \n",
      "  BatchNorm2D-12     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "      ReLU-6         [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \n",
      "     Conv2D-13       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \n",
      "  BatchNorm2D-13     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "     Conv2D-11       [[1, 128, 28, 28]]    [1, 256, 14, 14]       32,768     \n",
      "  BatchNorm2D-11     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "   BasicBlock-5      [[1, 128, 28, 28]]    [1, 256, 14, 14]          0       \n",
      "     Conv2D-14       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \n",
      "  BatchNorm2D-14     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "      ReLU-7         [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \n",
      "     Conv2D-15       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \n",
      "  BatchNorm2D-15     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "   BasicBlock-6      [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \n",
      "     Conv2D-17       [[1, 256, 14, 14]]     [1, 512, 7, 7]       1,179,648   \n",
      "  BatchNorm2D-17      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "      ReLU-8          [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "     Conv2D-18        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296   \n",
      "  BatchNorm2D-18      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "     Conv2D-16       [[1, 256, 14, 14]]     [1, 512, 7, 7]        131,072    \n",
      "  BatchNorm2D-16      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "   BasicBlock-7      [[1, 256, 14, 14]]     [1, 512, 7, 7]           0       \n",
      "     Conv2D-19        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296   \n",
      "  BatchNorm2D-19      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "      ReLU-9          [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "     Conv2D-20        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296   \n",
      "  BatchNorm2D-20      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "   BasicBlock-8       [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "AdaptiveAvgPool2D-1   [[1, 512, 7, 7]]      [1, 512, 1, 1]           0       \n",
      "     Linear-1            [[1, 512]]             [1, 4]             2,052     \n",
      "===============================================================================\n",
      "Total params: 11,188,164\n",
      "Trainable params: 11,178,564\n",
      "Non-trainable params: 9,600\n",
      "-------------------------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 57.04\n",
      "Params size (MB): 42.68\n",
      "Estimated Total Size (MB): 100.30\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'total_params': 11188164, 'trainable_params': 11178564}"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 summary 观察网络信息\n",
    "model.summary(input_size=(1, 3, 224, 224), dtype='float32')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:45:41.948368Z",
     "start_time": "2024-04-14T17:45:41.784127Z"
    }
   },
   "id": "447241548baab581",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8ba14f87476e42c9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 调用Paddle的VisualDL模块，保存信息到目录中。\n",
    "#log_dir (str) - 输出日志保存的路径。\n",
    "callback = paddle.callbacks.VisualDL(log_dir='visualdl_log_dir')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:45:41.953444Z",
     "start_time": "2024-04-14T17:45:41.949487Z"
    }
   },
   "id": "909a9fae18ee48f8",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#通过Model.prepare接口来对训练进行提前的配置准备工作，包括设置模型优化器，Loss计算方法，精度计算方法等\n",
    "# 优化器API文档： https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/optimizer/Overview_cn.html#paddle-optimizer\n",
    "\n",
    "# 学习率衰减策略\n",
    "# 学习率衰减策略 API 文档：https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/optimizer/Overview_cn.html#about-lr\n",
    "scheduler_StepDecay = paddle.optimizer.lr.StepDecay(learning_rate=0.1, step_size=50, gamma=0.9, verbose=False)\n",
    "scheduler_PiecewiseDecay = paddle.optimizer.lr.PiecewiseDecay(boundaries=[100, 1000, 4000, 5000, 6000],values=[0.1, 0.5, 0.01, 0.005, 0.001, 0.0005], verbose=False)\n",
    "\n",
    "# 尝试使用 SGD、Momentum 方法\n",
    "sgd = paddle.optimizer.SGD(\n",
    "    learning_rate=scheduler_StepDecay,\n",
    "    parameters=model.parameters())\n",
    "\n",
    "adam = paddle.optimizer.Adam(\n",
    "    learning_rate=0.01,  #调参\n",
    "    parameters=model.parameters())\n",
    "\n",
    "model.prepare(optimizer=adam,  # adam\n",
    "              loss=paddle.nn.CrossEntropyLoss(),\n",
    "              metrics=paddle.metric.Accuracy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:45:41.961279Z",
     "start_time": "2024-04-14T17:45:41.955568Z"
    }
   },
   "id": "747a69731cf6ebc8",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Place(cpu)\n"
     ]
    }
   ],
   "source": [
    "# 查看当前计算设备\n",
    "device = paddle.device.get_device()\n",
    "print(device)\n",
    "# 使用CPU训练\n",
    "device = paddle.set_device('cpu')  # or 'cpu'\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:45:41.967626Z",
     "start_time": "2024-04-14T17:45:41.962349Z"
    }
   },
   "id": "51f695f8d10b1088",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\nn\\layer\\norm.py:824: UserWarning: When training, we now always track global mean and variance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step   80/2904 [..............................] - loss: 0.5030 - acc: 0.2875 - ETA: 21:50 - 464ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6 (_thread_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\etc\\profile\\python\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"E:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"D:\\etc\\profile\\python\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"E:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\io\\dataloader\\dataloader_iter.py\", line 235, in _thread_loop\n",
      "    batch = self._dataset_fetcher.fetch(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\io\\dataloader\\fetcher.py\", line 77, in fetch\n",
      "    data.append(self.dataset[idx])\n",
      "                ~~~~~~~~~~~~^^^^^\n",
      "  File \"C:\\Users\\24603\\AppData\\Local\\Temp\\ipykernel_22216\\3013294970.py\", line 76, in __getitem__\n",
      "  File \"E:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\vision\\datasets\\folder.py\", line 267, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\vision\\datasets\\folder.py\", line 307, in default_loader\n",
      "    return pil_loader(path)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\vision\\datasets\\folder.py\", line 291, in pil_loader\n",
      "    with open(path, 'rb') as f:\n",
      "         ^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './data/splitted_training_data/train_images\\\\M2\\\\1145.png'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step   90/2904 [..............................] - loss: 3.1482 - acc: 0.2667 - ETA: 21:47 - 465ms/step"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 9\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# fit API文档： https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/Model_cn.html#fit-train-data-none-eval-data-none-batch-size-1-epochs-1-eval-freq-1-log-freq-10-save-dir-none-save-freq-1-verbose-2-drop-last-false-shuffle-true-num-workers-0-callbacks-none\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# 启动模型训练，指定训练数据集，设置训练轮次，设置每次数据集计算的批次大小，设置日志格式\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m#如果提示内存不足，可以尝试将batch_size调低\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m#verbose：日志显示，0为不在标准输出流输出日志信息,1为输出进度条记录，2为每个epoch输出一行记录;1为输出进度条记录，2为每个epoch输出一行记录\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m          \u001B[49m\u001B[43mval_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m          \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m          \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m          \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m          \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\hapi\\model.py:1986\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, train_data, eval_data, batch_size, epochs, eval_freq, log_freq, save_dir, save_freq, verbose, drop_last, shuffle, num_workers, callbacks, accumulate_grad_batches, num_iters)\u001B[0m\n\u001B[0;32m   1984\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m   1985\u001B[0m     cbks\u001B[38;5;241m.\u001B[39mon_epoch_begin(epoch)\n\u001B[1;32m-> 1986\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_one_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcbks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1987\u001B[0m     cbks\u001B[38;5;241m.\u001B[39mon_epoch_end(epoch, logs)\n\u001B[0;32m   1989\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m do_eval \u001B[38;5;129;01mand\u001B[39;00m epoch \u001B[38;5;241m%\u001B[39m eval_freq \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32mE:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\hapi\\model.py:2333\u001B[0m, in \u001B[0;36mModel._run_one_epoch\u001B[1;34m(self, data_loader, callbacks, mode, logs)\u001B[0m\n\u001B[0;32m   2327\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m   2328\u001B[0m     _inputs\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m   2329\u001B[0m         (step \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accumulate \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m   2330\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m step \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(data_loader)\n\u001B[0;32m   2331\u001B[0m     )\n\u001B[1;32m-> 2333\u001B[0m outs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m_batch\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_inputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2335\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_metrics \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loss:\n\u001B[0;32m   2336\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m [[\u001B[38;5;28mfloat\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m outs[\u001B[38;5;241m0\u001B[39m]]]\n",
      "File \u001B[1;32mE:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\hapi\\model.py:1247\u001B[0m, in \u001B[0;36mModel.train_batch\u001B[1;34m(self, inputs, labels, update)\u001B[0m\n\u001B[0;32m   1196\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_batch\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, labels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, update\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m   1197\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1198\u001B[0m \n\u001B[0;32m   1199\u001B[0m \u001B[38;5;124;03m    Run one training step on one batch of data. And using `update` indicates\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1245\u001B[0m \n\u001B[0;32m   1246\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1247\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_adapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mupdate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1248\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m in_dynamic_mode() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_info \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1249\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_inputs()\n",
      "File \u001B[1;32mE:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\hapi\\model.py:844\u001B[0m, in \u001B[0;36mDynamicGraphAdapter.train_batch\u001B[1;34m(self, inputs, labels, update)\u001B[0m\n\u001B[0;32m    842\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mddp_model(\u001B[38;5;241m*\u001B[39m[to_variable(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m inputs])\n\u001B[0;32m    843\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 844\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnetwork\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mto_variable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    846\u001B[0m losses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39m_loss(\u001B[38;5;241m*\u001B[39m(to_list(outputs) \u001B[38;5;241m+\u001B[39m labels))\n\u001B[0;32m    847\u001B[0m losses \u001B[38;5;241m=\u001B[39m to_list(losses)\n",
      "File \u001B[1;32mE:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:1429\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1420\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1421\u001B[0m     (\u001B[38;5;129;01mnot\u001B[39;00m in_to_static_mode())\n\u001B[0;32m   1422\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1426\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m in_profiler_mode())\n\u001B[0;32m   1427\u001B[0m ):\n\u001B[0;32m   1428\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_once(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1429\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1430\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1431\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dygraph_call_func(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mE:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\vision\\models\\resnet.py:337\u001B[0m, in \u001B[0;36mResNet.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    335\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer1(x)\n\u001B[0;32m    336\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer2(x)\n\u001B[1;32m--> 337\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer3\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    338\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer4(x)\n\u001B[0;32m    340\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwith_pool:\n",
      "File \u001B[1;32mE:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:1429\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1420\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1421\u001B[0m     (\u001B[38;5;129;01mnot\u001B[39;00m in_to_static_mode())\n\u001B[0;32m   1422\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1426\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m in_profiler_mode())\n\u001B[0;32m   1427\u001B[0m ):\n\u001B[0;32m   1428\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_once(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1429\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1430\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1431\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dygraph_call_func(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mE:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\nn\\layer\\container.py:614\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    612\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    613\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sub_layers\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[1;32m--> 614\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    615\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32mE:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:1431\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1429\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1430\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1431\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dygraph_call_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:1410\u001B[0m, in \u001B[0;36mLayer._dygraph_call_func\u001B[1;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1408\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1409\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1410\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1412\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m forward_post_hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_post_hooks\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[0;32m   1413\u001B[0m     hook_result \u001B[38;5;241m=\u001B[39m forward_post_hook(\u001B[38;5;28mself\u001B[39m, inputs, outputs)\n",
      "File \u001B[1;32mE:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\vision\\models\\resnet.py:117\u001B[0m, in \u001B[0;36mBasicBlock.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    114\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn1(out)\n\u001B[0;32m    115\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(out)\n\u001B[1;32m--> 117\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    118\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn2(out)\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdownsample \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mE:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:1431\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1429\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1430\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1431\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dygraph_call_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:1410\u001B[0m, in \u001B[0;36mLayer._dygraph_call_func\u001B[1;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1408\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1409\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1410\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1412\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m forward_post_hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_post_hooks\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[0;32m   1413\u001B[0m     hook_result \u001B[38;5;241m=\u001B[39m forward_post_hook(\u001B[38;5;28mself\u001B[39m, inputs, outputs)\n",
      "File \u001B[1;32mE:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\nn\\layer\\conv.py:715\u001B[0m, in \u001B[0;36mConv2D.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    707\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_padding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    708\u001B[0m     x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mpad(\n\u001B[0;32m    709\u001B[0m         x,\n\u001B[0;32m    710\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice,\n\u001B[0;32m    711\u001B[0m         mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_padding_mode,\n\u001B[0;32m    712\u001B[0m         data_format\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_format,\n\u001B[0;32m    713\u001B[0m     )\n\u001B[1;32m--> 715\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_nd\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    716\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    717\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    718\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    719\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstride\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    720\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_updated_padding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    721\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpadding_algorithm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_padding_algorithm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    722\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdilation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dilation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    723\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_groups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    724\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    725\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchannel_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_channel_dim\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    726\u001B[0m \u001B[43m    \u001B[49m\u001B[43mop_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_op_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    727\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cudnn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_use_cudnn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    728\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    729\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32mE:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\nn\\functional\\conv.py:128\u001B[0m, in \u001B[0;36m_conv_nd\u001B[1;34m(x, weight, bias, stride, padding, padding_algorithm, dilation, groups, data_format, channel_dim, op_type, use_cudnn, use_mkldnn, name)\u001B[0m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_conv_nd\u001B[39m(\n\u001B[0;32m    111\u001B[0m     x,\n\u001B[0;32m    112\u001B[0m     weight,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    125\u001B[0m ):\n\u001B[0;32m    126\u001B[0m     \u001B[38;5;66;03m# Due to the poor performance of NHWC, we transpose the input to NCHW.\u001B[39;00m\n\u001B[0;32m    127\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m in_dynamic_or_pir_mode() \u001B[38;5;129;01mand\u001B[39;00m op_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconv2d\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 128\u001B[0m         pre_bias \u001B[38;5;241m=\u001B[39m \u001B[43m_C_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    129\u001B[0m \u001B[43m            \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    130\u001B[0m \u001B[43m            \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    131\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    132\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    133\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpadding_algorithm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    134\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    136\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    137\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    138\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m bias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    139\u001B[0m             new_shape \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(x\u001B[38;5;241m.\u001B[39mshape)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# fit API文档： https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/Model_cn.html#fit-train-data-none-eval-data-none-batch-size-1-epochs-1-eval-freq-1-log-freq-10-save-dir-none-save-freq-1-verbose-2-drop-last-false-shuffle-true-num-workers-0-callbacks-none\n",
    "\n",
    "# 启动模型训练，指定训练数据集，设置训练轮次，设置每次数据集计算的批次大小，设置日志格式\n",
    "#epochs：总共训练的轮数\n",
    "#batch_size：一个批次的样本数量\n",
    "#如果提示内存不足，可以尝试将batch_size调低\n",
    "#verbose：日志显示，0为不在标准输出流输出日志信息,1为输出进度条记录，2为每个epoch输出一行记录;1为输出进度条记录，2为每个epoch输出一行记录\n",
    "\n",
    "model.fit(train_dataset,\n",
    "          val_dataset,\n",
    "          epochs=1,\n",
    "          batch_size=2,\n",
    "          callbacks=callback,\n",
    "          verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:46:25.818786Z",
     "start_time": "2024-04-14T17:45:41.968703Z"
    }
   },
   "id": "2e1ddae510334aca",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#模型评估\n",
    "#对于训练好的模型进行评估操作可以使用 model.evaluate 接口；操作结束后会根据 prepare 接口配置的 loss 和 metric 来进行相关指标计算返回。\n",
    "# 评价指标参考文档：https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/Model_cn.html#evaluate-eval-data-batch-size-1-log-freq-10-verbose-2-num-workers-0-callbacks-none\n",
    "model.evaluate(test_dataset, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:46:25.819794Z",
     "start_time": "2024-04-14T17:46:25.819794Z"
    }
   },
   "id": "59315ed2fdf29ad3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#模型保存\n",
    "model.save('./saved_model/saved_model')  # save for training"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:46:25.820888Z",
     "start_time": "2024-04-14T17:46:25.820888Z"
    }
   },
   "id": "dcb089a314a16a3f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#预测模型\n",
    "results = model.predict(test_dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ff51e8f188047ac",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 观察 result\n",
    "print(type(results)) #list\n",
    "print(len(results)) #len == 1\n",
    "\n",
    "# 一行一行打印结果\n",
    "for i in results[0]:\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-14T17:46:25.821893Z"
    }
   },
   "id": "fdfdc6e32176b00f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 将结果用 softmax 处理后变成概率值\n",
    "x = paddle.to_tensor(results[0])\n",
    "m = paddle.nn.Softmax()\n",
    "out = m(x)\n",
    "print(out)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-14T17:46:25.822936Z"
    }
   },
   "id": "a6235988d42b417",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#用一个字典，指名标签对应的数值\n",
    "label_dic = {}\n",
    "for i, label in enumerate(labels):\n",
    "    label_dic[i] = label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-14T17:46:25.824042Z"
    }
   },
   "id": "c05b151ae53b8ba7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#预测标签结果写入predict_labels\n",
    "predict_labels = []\n",
    "#依次取results[0]中的每个图片的预测数组\n",
    "for result in results[0]: \n",
    "    #np.argmax:返回一个numpy数组中的最大值的索引\n",
    "    #注意：索引是标签，不是返回数据的最大值\n",
    "    lab_index = np.argmax(result)\n",
    "    lab = label_dic[lab_index]\n",
    "    predict_labels.append(lab)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-14T17:46:25.825121Z"
    }
   },
   "id": "c0e164ff67c97592",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#看一下预测结果\n",
    "print(predict_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-14T17:46:25.826125Z"
    }
   },
   "id": "9215f73368026c8f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "final_result = [ ]\n",
    "file_name_test = train_parameters['test_list_dir'] \n",
    "f = open(file_name_test, 'r') \n",
    "#按行读取数据\n",
    "data = f.readlines()\n",
    "for i in range(len(data)):\n",
    "    #将每行数据按照空格分割成2部分，并取第一部分的路径名和图像文件名，例如:R0/1.png\n",
    "    img_path = data[i].split('\\t')[0]\n",
    "    final_result.append(img_path + ',' + str(predict_labels[i]) + '\\n')\n",
    "\n",
    "f.close( )\n",
    "\n",
    "with open('result.csv',\"w\") as f: \n",
    "    f.writelines(final_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-14T17:46:25.826125Z"
    }
   },
   "id": "3bd0c8db05d7c244",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

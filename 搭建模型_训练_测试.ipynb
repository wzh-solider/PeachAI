{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#os ： OS模块提供了非常丰富的方法用来处理文件和目录。\n",
    "#sys：sys模块提供了一系列有关Python运行环境的变量和函数。\n",
    "#shutil:用于文件拷贝的模块 \n",
    "#numpy：numpy 是 Python 语言的一个扩展程序库，支持大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。\n",
    "#random：Python中的random模块用于生成随机数。\n",
    "#paddle.vision.datasets：该模块包含数据加载的相关函数，比如可以用来加载常用的数据集等，如mnist。\n",
    "#paddle.vision.transforms:该模块包含对图像进行转换的函数，比如把HWC格式的图片，转变成CHW模式的输入张量。也包含飞桨框架对于图像预处理的方式，可以快速完成常见的图像预处理，如调整色调、对比度，图像大小等；\n",
    "#paddle.io.Dataset:高模块包含了飞桨框架数据加载方式，可以“一键”完成数据的批加载与异步加载。\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import paddle\n",
    "import random\n",
    "from paddle.io import Dataset, DataLoader\n",
    "from paddle.vision.datasets import DatasetFolder, ImageFolder\n",
    "from paddle.vision import transforms as T"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:04:18.679682Z",
     "start_time": "2024-04-14T12:04:18.675736Z"
    }
   },
   "id": "340e37c3d4c0e54d",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# '''\n",
    "# 参数配置：\n",
    "# 'train_data_dir'是提供的经增强后的原始训练集；\n",
    "# 'test_image_dir'是提供的原始测试集；\n",
    "# 'train_image_dir'和'eval_image_dir'是由原始训练集经拆分后生成的实际训练集和验证集\n",
    "# 'train_list_dir'和'test_list_dir'是生成的txt文件路径\n",
    "# 'saved_model' 存放训练结果的文件夹\n",
    "# '''\n",
    "train_parameters = {\n",
    "    'train_image_dir': './data/splitted_training_data/train_images',\n",
    "    'eval_image_dir': './data/splitted_training_data/eval_images',\n",
    "    'test_image_dir': './data/enhancement_data/test',\n",
    "    'train_data_dir': './data/enhancement_data/train',\n",
    "    'train_list_dir': './data/enhancement_data/train.txt',\n",
    "    'test_list_dir': './data/enhancement_data/test.txt',\n",
    "    'saved_model': './saved_model/'\n",
    "}\n",
    "\n",
    "#数据集的4个类别标签\n",
    "labels = ['R0', 'B1', 'M2', 'S3']\n",
    "labels.sort()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:04:18.697589Z",
     "start_time": "2024-04-14T12:04:18.693109Z"
    }
   },
   "id": "b4c6c18e4a0c066d",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#准备生成训练集文件名、标签名的txt文件\n",
    "write_file_name = train_parameters['train_list_dir']\n",
    "\n",
    "#以写方式打开write_file_name文件\n",
    "with open(write_file_name, \"w\") as write_file:\n",
    "    #针对不同的分类标签分别录入\n",
    "    for label in labels:\n",
    "        #建立空列表，用于保存图片名\n",
    "        file_list = []\n",
    "        #用于找到该标签路径下的所有图片.\n",
    "        train_txt_dir = train_parameters['train_data_dir'] + '/' + label + '/'\n",
    "\n",
    "        for file_name in os.listdir(train_txt_dir):\n",
    "            dir_name = label\n",
    "            temp_line = dir_name + '/' + file_name + '\\t' + label + '\\n'  # 例如：\"B1/101.png\tB1\"\n",
    "            write_file.write(temp_line)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:04:18.718499Z",
     "start_time": "2024-04-14T12:04:18.700851Z"
    }
   },
   "id": "7a22f6855f6393e6",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#准备生成测试集文件名、标签名的txt文件\n",
    "write_file_name = train_parameters['test_list_dir']\n",
    "\n",
    "#以写方式打开write_file_name文件\n",
    "with open(write_file_name, \"w\") as write_file:\n",
    "    #针对不同的分类标签分别录入\n",
    "    for label in labels:\n",
    "        #建立空列表，用于保存图片名\n",
    "        file_list = []\n",
    "        #用于找到该标签路径下的所有图片.\n",
    "        train_txt_dir = train_parameters['test_image_dir'] + '/' + label + '/'\n",
    "\n",
    "        for file_name in os.listdir(train_txt_dir):\n",
    "            dir_name = label\n",
    "            temp_line = dir_name + '/' + file_name + '\\t' + label + '\\n'  # 例如：\"B1/101.png\tB1\"\n",
    "            write_file.write(temp_line)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:04:18.725275Z",
     "start_time": "2024-04-14T12:04:18.719563Z"
    }
   },
   "id": "824e3679d30e2822",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#判断splitted_training_data文件夹是否存在，如果不存在就新建一个\n",
    "if not os.path.exists('data/splitted_training_data'):\n",
    "    os.makedirs('data/splitted_training_data')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:04:18.731502Z",
     "start_time": "2024-04-14T12:04:18.728534Z"
    }
   },
   "id": "4ae867d3577c06b4",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#定义一个函数，来拆分训练集、验证集\n",
    "def create_train_eval():\n",
    "    '''\n",
    "    划分训练集和验证集\n",
    "    '''\n",
    "    train_dir = train_parameters['train_image_dir']\n",
    "    eval_dir = train_parameters['eval_image_dir']\n",
    "    train_list_path = train_parameters['train_list_dir']\n",
    "    train_data_dir = train_parameters['train_data_dir']\n",
    "\n",
    "    print('creating training and eval images')\n",
    "    #如果文件夹不存在，建立相应的文件夹\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.mkdir(train_dir)\n",
    "    if not os.path.exists(eval_dir):\n",
    "        os.mkdir(eval_dir)\n",
    "\n",
    "        #打开txt文件，分割数据\n",
    "    file_name = train_list_path\n",
    "    f = open(file_name, 'r')\n",
    "    #按行读取数据\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        #将每行数据按照空格分割成2部分，并取第一部分的路径名和图像文件名，例如:R0/1.png\n",
    "        img_path = lines[i].split('\\t')[0]\n",
    "        #取第二部分的标签，例如:R0\n",
    "        class_label = lines[i].split('\\t')[1].strip('\\n')\n",
    "        # 每8张图片取一个做验证数据,其他用于训练\n",
    "        if i % 8 == 0:\n",
    "            #把目录和文件名合成一个路径\n",
    "            eval_target_dir = os.path.join(eval_dir, class_label)\n",
    "            #将总的文件路径与当前图像的文件名合到一起，实际就是得到训练集图像所在的文件夹下的图像名   \n",
    "            eval_img_path = os.path.join(train_data_dir, img_path)\n",
    "            if not os.path.exists(eval_target_dir):\n",
    "                os.mkdir(eval_target_dir)\n",
    "                #将图片复制到验证集指定标签的文件夹下      \n",
    "            shutil.copy(eval_img_path, eval_target_dir)\n",
    "        else:\n",
    "            train_target_dir = os.path.join(train_dir, class_label)\n",
    "            train_img_path = os.path.join(train_data_dir, img_path)\n",
    "            if not os.path.exists(train_target_dir):\n",
    "                os.mkdir(train_target_dir)\n",
    "            shutil.copy(train_img_path, train_target_dir)\n",
    "    print('划分训练集和验证集完成！')\n",
    "\n",
    "# 制作数据集，如果已经做好了，就请将代码注释掉\n",
    "# create_train_eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:04:18.746817Z",
     "start_time": "2024-04-14T12:04:18.740427Z"
    }
   },
   "id": "7322e039ad424623",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class PeachDataset(Dataset):\n",
    "    \"\"\"\n",
    "    步骤一：继承paddle.io.Dataset类\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mode='train'):\n",
    "        \"\"\"\n",
    "        步骤二：实现构造函数，定义数据读取方式，划分训练、验证和测试数据集\n",
    "        \"\"\"\n",
    "        super(PeachDataset, self).__init__()\n",
    "        train_image_dir = train_parameters['train_image_dir']  #训练集的路径\n",
    "        eval_image_dir = train_parameters['eval_image_dir']\n",
    "        test_image_dir = train_parameters['test_image_dir']\n",
    "\n",
    "        '''         '''\n",
    "        #transform数据增强函数，这里仅对图片的打开方式进行了转换            \n",
    "        #这里用Transpose()将图片的打开方式(宽, 高, 通道数)更改为PaddlePaddle读取的方式是(通道数, 宽, 高)\n",
    "        mean = [127.5, 127.5, 127.5]  # 归一化，均值\n",
    "        std = [127.5, 127.5, 127.5]  # 归一化，标注差 \n",
    "        transform_train = T.Compose([T.ColorJitter(0.4, 0.4, 0.4, 0.4)\n",
    "                                        , T.Resize(size=(224, 224))\n",
    "                                        , T.Transpose()\n",
    "                                        , T.Normalize(mean, std)\n",
    "                                     ])\n",
    "        transform_eval = T.Compose([T.Resize(size=(224, 224))\n",
    "                                       , T.Transpose()\n",
    "                                       , T.Normalize(mean, std)\n",
    "                                    ])\n",
    "        transform_test = T.Compose([T.Resize(size=(224, 224))\n",
    "                                       , T.Transpose()\n",
    "                                       , T.Normalize(mean, std)\n",
    "                                    ])\n",
    "\n",
    "        '''         \n",
    "        # 参考API：https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/Overview_cn.html#about-transforms\n",
    "        #这里用Transpose()将图片的打开方式(宽, 高, 通道数)更改为PaddlePaddle读取的方式是(通道数, 宽, 高)\n",
    "        # ColorJitter 随机调整图像的亮度，对比度，饱和度和色调。\n",
    "        # hflip 对输入图像进行水平翻转。        \n",
    "        # Normalize 归一化。mean = [127.5, 127.5, 127.5]，std = [127.5, 127.5, 127.5]\n",
    "        # RandomHorizontalFlip 基于概率来执行图片的水平翻转。\n",
    "        # RandomVerticalFlip 基于概率来执行图片的垂直翻转。\n",
    "        mean = [127.5, 127.5, 127.5] # 归一化，均值\n",
    "        std = [127.5, 127.5, 127.5] # 归一化，标注差 \n",
    "        transform_train = T.Compose([T.Resize(size=(224,224)), \n",
    "                                     T.Transpose(),                                \n",
    "                                     T.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "                                     T.RandomHorizontalFlip(prob=0.5,),\n",
    "                                     T.RandomVerticalFlip(prob=0.5,),\n",
    "                                     T.Normalize(mean, std)])\n",
    "        transform_eval = T.Compose([T.Resize(size=(224,224)), T.Transpose()])\n",
    "        transform_test = T.Compose([T.Resize(size=(224,224)), T.Transpose()])\n",
    "        '''\n",
    "\n",
    "        #飞桨推荐使用 paddle.io.DataLoader 完成数据的加载，生成一个可以加载数据的迭代器\n",
    "        # 参考API:https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/io/DataLoader_cn.html#cn-api-fluid-io-dataloader\n",
    "        #加载训练集，train_data_folder 是一个迭代器\n",
    "        # 参考API：https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/datasets/DatasetFolder_cn.html#datasetfolder\n",
    "        train_data_folder = DatasetFolder(train_image_dir, transform=transform_train)\n",
    "        #加载验证集，eval_data_folder 是一个迭代器\n",
    "        eval_data_folder = DatasetFolder(eval_image_dir, transform=transform_eval)\n",
    "        #加载测试集，test_data_folder 是一个迭代器\n",
    "        test_data_folder = DatasetFolder(test_image_dir, transform=transform_test)\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "            self.data = train_data_folder\n",
    "        elif self.mode == 'eval':\n",
    "            self.data = eval_data_folder\n",
    "        elif self.mode == 'test':\n",
    "            self.data = test_data_folder\n",
    "\n",
    "    # 每次迭代时返回数据和对应的标签\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        步骤三：实现__getitem__方法，定义指定index时如何获取数据，并返回单条数据（训练数据，对应的标签）\n",
    "        \"\"\"\n",
    "        data = np.array(self.data[index][0]).astype('float32')\n",
    "\n",
    "        label = np.array([self.data[index][1]]).astype('int64')\n",
    "\n",
    "        return data, label\n",
    "\n",
    "    # 返回整个数据集的总数\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        步骤四：实现__len__方法，返回数据集总数目\n",
    "        \"\"\"\n",
    "        return len(self.data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:04:18.755493Z",
     "start_time": "2024-04-14T12:04:18.747875Z"
    }
   },
   "id": "c458ab62832e2857",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#用自定义的PeachDataset类，加载自己的数据集\n",
    "train_dataset = PeachDataset(mode='train')\n",
    "val_dataset = PeachDataset(mode='eval')\n",
    "test_dataset = PeachDataset(mode='test')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:04:18.826534Z",
     "start_time": "2024-04-14T12:04:18.756502Z"
    }
   },
   "id": "8276f74e1dd0f1b8",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opencv 版本号为：4.9.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# DataLoader 示例代码\n",
    "\n",
    "# 加载库\n",
    "import cv2 as cv  #使用 OpenCV\n",
    "\n",
    "print(\"opencv 版本号为：\" + cv.__version__)  #查看版本号\n",
    "# 事实上在使用 OpenCV之前应该安装该类库，但是由于使用了 AI-Studio，所以系统已经替开发者预先安装好了： opencv-python 4.1.1.26       \n",
    "from matplotlib import pyplot as plt  #在该页面画图\n",
    "%matplotlib inline \n",
    "\n",
    "# 构造一个 DataLoader\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=2,\n",
    "                         shuffle=True,\n",
    "                         drop_last=True,\n",
    "                         num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:04:18.834590Z",
     "start_time": "2024-04-14T12:04:18.828698Z"
    }
   },
   "id": "37945b6eb1cae757",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini_batch 的类型为：<class 'list'>\n",
      "mini_batch 的大小为：2\n",
      "(3, 224, 224)\n",
      "(3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "# 使用 DataLoader 来遍历数据集\n",
    "for mini_batch in test_loader:  # 从 DataLoader 中获取 mini_batch \n",
    "    print(\"mini_batch 的类型为：\" + str(type(mini_batch)))\n",
    "    pic_list = mini_batch[0]  #图片数据\n",
    "    label_list = mini_batch[1]  #标记\n",
    "    print(\"mini_batch 的大小为：\" + str(len(pic_list)))\n",
    "\n",
    "    # 将图片显示转化为 numpy 格式，并且将内部的数字设置为 整数类型\n",
    "    pic_1 = pic_list[0]\n",
    "    pic_2 = pic_list[1]\n",
    "    arr1 = np.asarray(pic_1, dtype=np.float64)\n",
    "    print(arr1.shape)\n",
    "    arr2 = np.asarray(pic_2, dtype=np.float64)\n",
    "    print(arr2.shape)\n",
    "\n",
    "    break  #由于是示例，所以仅拿出第一个 mini_batch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:04:18.859654Z",
     "start_time": "2024-04-14T12:04:18.835754Z"
    }
   },
   "id": "75353e4e8724dc25",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 把获取到的图片数据展示出来\n",
    "# arr1 = arr1 / 255 # 把每一个像素都变到 0-1 之间\n",
    "# r = arr1[0]\n",
    "# g = arr1[1]\n",
    "# b = arr1[2]\n",
    "# img = cv.merge([r, g, b])\n",
    "# \n",
    "# plt.imshow(img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:04:18.864946Z",
     "start_time": "2024-04-14T12:04:18.861815Z"
    }
   },
   "id": "95ae01f36911f7db",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 使用内置的模型,这边可以选择多种不同网络，这里选了resnet50网络\n",
    "#pretrained (bool，可选) - 是否加载在imagenet数据集上的预训练权重\n",
    "model = paddle.vision.models.resnet18(pretrained=True, num_classes=4)\n",
    "\n",
    "#尝试不同的网络结构：MobileNetV2\n",
    "# MobileNetV2参考文档：https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/models/MobileNetV2_cn.html\n",
    "# model = paddle.vision.models.mobilenet_v2(pretrained=True, num_classes=4)    \n",
    "\n",
    "#使用paddle.Model完成模型的封装，将网络结构组合成一个可快速使用高层API进行训练和预测的类。\n",
    "model = paddle.Model(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:04:20.158836Z",
     "start_time": "2024-04-14T12:04:18.866041Z"
    }
   },
   "id": "1e273f2031247d08",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "   Layer (type)         Input Shape          Output Shape         Param #    \n",
      "===============================================================================\n",
      "     Conv2D-41       [[1, 3, 224, 224]]   [1, 64, 112, 112]        9,408     \n",
      "  BatchNorm2D-41    [[1, 64, 112, 112]]   [1, 64, 112, 112]         256      \n",
      "      ReLU-19       [[1, 64, 112, 112]]   [1, 64, 112, 112]          0       \n",
      "    MaxPool2D-3     [[1, 64, 112, 112]]    [1, 64, 56, 56]           0       \n",
      "     Conv2D-42       [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \n",
      "  BatchNorm2D-42     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \n",
      "      ReLU-20        [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "     Conv2D-43       [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \n",
      "  BatchNorm2D-43     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \n",
      "   BasicBlock-17     [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "     Conv2D-44       [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \n",
      "  BatchNorm2D-44     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \n",
      "      ReLU-21        [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "     Conv2D-45       [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \n",
      "  BatchNorm2D-45     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \n",
      "   BasicBlock-18     [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "     Conv2D-47       [[1, 64, 56, 56]]     [1, 128, 28, 28]       73,728     \n",
      "  BatchNorm2D-47     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "      ReLU-22        [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "     Conv2D-48       [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456    \n",
      "  BatchNorm2D-48     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "     Conv2D-46       [[1, 64, 56, 56]]     [1, 128, 28, 28]        8,192     \n",
      "  BatchNorm2D-46     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "   BasicBlock-19     [[1, 64, 56, 56]]     [1, 128, 28, 28]          0       \n",
      "     Conv2D-49       [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456    \n",
      "  BatchNorm2D-49     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "      ReLU-23        [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "     Conv2D-50       [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456    \n",
      "  BatchNorm2D-50     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "   BasicBlock-20     [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "     Conv2D-52       [[1, 128, 28, 28]]    [1, 256, 14, 14]       294,912    \n",
      "  BatchNorm2D-52     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "      ReLU-24        [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \n",
      "     Conv2D-53       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \n",
      "  BatchNorm2D-53     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "     Conv2D-51       [[1, 128, 28, 28]]    [1, 256, 14, 14]       32,768     \n",
      "  BatchNorm2D-51     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "   BasicBlock-21     [[1, 128, 28, 28]]    [1, 256, 14, 14]          0       \n",
      "     Conv2D-54       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \n",
      "  BatchNorm2D-54     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "      ReLU-25        [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \n",
      "     Conv2D-55       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \n",
      "  BatchNorm2D-55     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "   BasicBlock-22     [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \n",
      "     Conv2D-57       [[1, 256, 14, 14]]     [1, 512, 7, 7]       1,179,648   \n",
      "  BatchNorm2D-57      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "      ReLU-26         [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "     Conv2D-58        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296   \n",
      "  BatchNorm2D-58      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "     Conv2D-56       [[1, 256, 14, 14]]     [1, 512, 7, 7]        131,072    \n",
      "  BatchNorm2D-56      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "   BasicBlock-23     [[1, 256, 14, 14]]     [1, 512, 7, 7]           0       \n",
      "     Conv2D-59        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296   \n",
      "  BatchNorm2D-59      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "      ReLU-27         [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "     Conv2D-60        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296   \n",
      "  BatchNorm2D-60      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "   BasicBlock-24      [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "AdaptiveAvgPool2D-3   [[1, 512, 7, 7]]      [1, 512, 1, 1]           0       \n",
      "     Linear-3            [[1, 512]]             [1, 4]             2,052     \n",
      "===============================================================================\n",
      "Total params: 11,188,164\n",
      "Trainable params: 11,178,564\n",
      "Non-trainable params: 9,600\n",
      "-------------------------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 57.04\n",
      "Params size (MB): 42.68\n",
      "Estimated Total Size (MB): 100.30\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'total_params': 11188164, 'trainable_params': 11178564}"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 summary 观察网络信息\n",
    "model.summary(input_size=(1, 3, 224, 224), dtype='float32')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:04:20.265036Z",
     "start_time": "2024-04-14T12:04:20.159901Z"
    }
   },
   "id": "447241548baab581",
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8ba14f87476e42c9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 调用Paddle的VisualDL模块，保存信息到目录中。\n",
    "#log_dir (str) - 输出日志保存的路径。\n",
    "callback = paddle.callbacks.VisualDL(log_dir='visualdl_log_dir')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:04:20.269150Z",
     "start_time": "2024-04-14T12:04:20.266104Z"
    }
   },
   "id": "909a9fae18ee48f8",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#通过Model.prepare接口来对训练进行提前的配置准备工作，包括设置模型优化器，Loss计算方法，精度计算方法等\n",
    "# 优化器API文档： https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/optimizer/Overview_cn.html#paddle-optimizer\n",
    "\n",
    "# 学习率衰减策略\n",
    "# 学习率衰减策略 API 文档：https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/optimizer/Overview_cn.html#about-lr\n",
    "scheduler_StepDecay = paddle.optimizer.lr.StepDecay(learning_rate=0.1, step_size=50, gamma=0.9, verbose=False)\n",
    "scheduler_PiecewiseDecay = paddle.optimizer.lr.PiecewiseDecay(boundaries=[100, 1000, 4000, 5000, 6000],values=[0.1, 0.5, 0.01, 0.005, 0.001, 0.0005], verbose=False)\n",
    "\n",
    "# 尝试使用 SGD、Momentum 方法\n",
    "sgd = paddle.optimizer.SGD(\n",
    "    learning_rate=scheduler_StepDecay,\n",
    "    parameters=model.parameters())\n",
    "\n",
    "adam = paddle.optimizer.Adam(\n",
    "    learning_rate=0.01,  #调参\n",
    "    parameters=model.parameters())\n",
    "\n",
    "model.prepare(optimizer=adam,  # adam\n",
    "              loss=paddle.nn.CrossEntropyLoss(),\n",
    "              metrics=paddle.metric.Accuracy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:04:20.276381Z",
     "start_time": "2024-04-14T12:04:20.270232Z"
    }
   },
   "id": "747a69731cf6ebc8",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Place(cpu)\n"
     ]
    }
   ],
   "source": [
    "# 查看当前计算设备\n",
    "device = paddle.device.get_device()\n",
    "print(device)\n",
    "# 使用CPU训练\n",
    "device = paddle.set_device('cpu')  # or 'cpu'\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:04:20.282690Z",
     "start_time": "2024-04-14T12:04:20.278462Z"
    }
   },
   "id": "51f695f8d10b1088",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/1\n",
      "step 2904/2904 [==============================] - loss: 0.4651 - acc: 0.4047 - 602ms/step          \n",
      "Eval begin...\n",
      "step 415/415 [==============================] - loss: 0.9715 - acc: 0.5518 - 123ms/step          \n",
      "Eval samples: 830\n"
     ]
    }
   ],
   "source": [
    "# fit API文档： https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/Model_cn.html#fit-train-data-none-eval-data-none-batch-size-1-epochs-1-eval-freq-1-log-freq-10-save-dir-none-save-freq-1-verbose-2-drop-last-false-shuffle-true-num-workers-0-callbacks-none\n",
    "\n",
    "# 启动模型训练，指定训练数据集，设置训练轮次，设置每次数据集计算的批次大小，设置日志格式\n",
    "#epochs：总共训练的轮数\n",
    "#batch_size：一个批次的样本数量\n",
    "#如果提示内存不足，可以尝试将batch_size调低\n",
    "#verbose：日志显示，0为不在标准输出流输出日志信息,1为输出进度条记录，2为每个epoch输出一行记录;1为输出进度条记录，2为每个epoch输出一行记录\n",
    "\n",
    "model.fit(train_dataset,\n",
    "          val_dataset,\n",
    "          epochs=1,\n",
    "          batch_size=2,\n",
    "          callbacks=callback,\n",
    "          verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:34:19.550801Z",
     "start_time": "2024-04-14T12:04:20.283786Z"
    }
   },
   "id": "2e1ddae510334aca",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "step 67/67 [==============================] - loss: 0.7953 - acc: 0.5821 - 70ms/step          \n",
      "Eval samples: 67\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'loss': [0.795268177986145], 'acc': 0.582089552238806}"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#模型评估\n",
    "#对于训练好的模型进行评估操作可以使用 model.evaluate 接口；操作结束后会根据 prepare 接口配置的 loss 和 metric 来进行相关指标计算返回。\n",
    "# 评价指标参考文档：https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/Model_cn.html#evaluate-eval-data-batch-size-1-log-freq-10-verbose-2-num-workers-0-callbacks-none\n",
    "model.evaluate(test_dataset, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:34:24.248746Z",
     "start_time": "2024-04-14T12:34:19.551861Z"
    }
   },
   "id": "59315ed2fdf29ad3",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#模型保存\n",
    "model.save('./saved_model/saved_model')  # save for training"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:34:24.492236Z",
     "start_time": "2024-04-14T12:34:24.249751Z"
    }
   },
   "id": "dcb089a314a16a3f",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict begin...\n",
      "step 67/67 [==============================] - 72ms/step          \n",
      "Predict samples: 67\n"
     ]
    }
   ],
   "source": [
    "#预测模型\n",
    "results = model.predict(test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:34:29.306941Z",
     "start_time": "2024-04-14T12:34:24.492236Z"
    }
   },
   "id": "6ff51e8f188047ac",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "1\n",
      "[[ 0.40576768  0.8601775  -1.465238   -0.36331972]]\n",
      "[[ 0.60238826  1.3793479  -1.7529192  -1.0881819 ]]\n",
      "[[ 0.66318554  1.4935445  -1.8879623  -1.1933609 ]]\n",
      "[[ 0.58703434  1.1057408  -1.4025886  -1.0400165 ]]\n",
      "[[ 0.3171487   0.8939666  -1.6674647  -0.08739716]]\n",
      "[[ 1.1986499  1.3292956 -1.1824696 -2.0925632]]\n",
      "[[ 0.63046473  1.5451624  -1.6561182  -1.579493  ]]\n",
      "[[ 0.51370704  1.0473548  -1.7095428  -0.5640062 ]]\n",
      "[[ 1.6203661  1.7644764 -1.3310684 -3.039494 ]]\n",
      "[[ 0.19653009  0.9715382  -1.7348814  -0.0810869 ]]\n",
      "[[ 1.3591175  1.4313431 -1.4671013 -2.1014411]]\n",
      "[[ 1.1005689  1.6024035 -1.5357833 -2.1216257]]\n",
      "[[ 1.2957975  1.5163928 -1.3622978 -2.35241  ]]\n",
      "[[ 0.24260807  1.2053908  -2.1050277  -0.09655425]]\n",
      "[[ 0.47433    1.0254498 -1.7851863 -0.3308874]]\n",
      "[[ 1.0321581  1.3464663 -1.3781836 -1.7773141]]\n",
      "[[-0.30551082  1.2629466  -3.163193    1.4257715 ]]\n",
      "[[-0.10391976  1.0722374  -2.464657    0.77453625]]\n",
      "[[ 0.42857397  1.1900136  -1.9591     -0.3910134 ]]\n",
      "[[ 0.45961916  1.5092968  -2.373923   -0.5358597 ]]\n",
      "[[ 0.8448706  1.2740993 -1.8095174 -1.1084558]]\n",
      "[[ 0.07995325  1.0509187  -2.2329948   0.39547205]]\n",
      "[[ 0.00989665  1.2906669  -1.8274248  -0.56098616]]\n",
      "[[ 1.5298799e-03  1.0003119e+00 -2.2009618e+00  5.1068991e-01]]\n",
      "[[-0.25473356  1.2498131  -3.0133824   1.1949298 ]]\n",
      "[[-0.2092493  1.0806351 -2.62458    1.0999936]]\n",
      "[[ 0.21997733  1.071424   -2.06068     0.08575296]]\n",
      "[[ 0.56166667  1.6023093  -2.1852355  -0.980062  ]]\n",
      "[[-0.15139543  0.99297357 -2.3287106   0.8589052 ]]\n",
      "[[ 0.14451438  1.202107   -2.539524    0.4379196 ]]\n",
      "[[ 0.30913204  0.997009   -1.7324331  -0.17294785]]\n",
      "[[ 0.61210734  1.3838673  -1.8837755  -0.97969925]]\n",
      "[[-0.24217142  1.156582   -2.8211982   1.1706191 ]]\n",
      "[[ 0.46076113  1.4630512  -2.3450727  -0.4747592 ]]\n",
      "[[-3.8250196  -0.01880415  5.16422    -4.178067  ]]\n",
      "[[-6.5738482 -0.4301253  9.194715  -6.7655168]]\n",
      "[[-3.3717961 -0.0328746  4.5847945 -3.655751 ]]\n",
      "[[-4.193408   -0.12155534  6.5090795  -5.4323297 ]]\n",
      "[[-4.2178817  -0.01635604  5.3410068  -4.210681  ]]\n",
      "[[-6.8024116  -0.38578433  9.2628355  -6.804684  ]]\n",
      "[[-6.4687867  -0.44911206  9.121946   -6.636304  ]]\n",
      "[[-3.631681   -0.11949734  5.2751083  -4.2125993 ]]\n",
      "[[-2.26254     0.13760561  3.4407256  -3.3462152 ]]\n",
      "[[-3.746476   -0.03265108  5.127612   -4.1951013 ]]\n",
      "[[-6.074742   -0.37403494  8.042385   -5.7255464 ]]\n",
      "[[-3.3768146  -0.03809015  5.093756   -4.3834805 ]]\n",
      "[[-3.635441   -0.06295349  5.6188602  -4.818464  ]]\n",
      "[[-3.8549082  -0.06258871  5.798944   -4.916552  ]]\n",
      "[[-3.691254   -0.10426934  5.958897   -5.097858  ]]\n",
      "[[-3.7329543 -0.0632035  6.0380445 -5.3116174]]\n",
      "[[-2.767251    0.00963931  4.316854   -3.7895129 ]]\n",
      "[[-5.4157534  -0.30232018  7.1221595  -5.0379534 ]]\n",
      "[[-0.09336211  1.0031295  -2.21653     0.6804905 ]]\n",
      "[[-0.17451863  1.1209444  -2.6043577   0.9702138 ]]\n",
      "[[-0.28260714  1.2217504  -3.0459356   1.3671952 ]]\n",
      "[[-0.22019328  1.1416453  -2.7224598   1.0807135 ]]\n",
      "[[-0.179299   1.1264353 -2.6449182  0.9466312]]\n",
      "[[-0.18086025  1.1579322  -2.7557666   1.0034572 ]]\n",
      "[[-0.208      1.0951385 -2.6428857  1.0694194]]\n",
      "[[-0.34131968  1.3358529  -3.3775828   1.5589211 ]]\n",
      "[[-0.2939697  1.2594218 -3.1312182  1.4058431]]\n",
      "[[-0.16212665  1.113125   -2.5773861   0.9659951 ]]\n",
      "[[-0.21136925  1.1885849  -2.818964    1.1270111 ]]\n",
      "[[-0.253389   1.188546  -2.9091134  1.2069224]]\n",
      "[[-0.2499123  1.2244582 -2.9623716  1.2574067]]\n",
      "[[-0.11452065  1.0668936  -2.4754243   0.8107337 ]]\n",
      "[[-0.25289637  1.1723152  -2.8796027   1.2069435 ]]\n"
     ]
    }
   ],
   "source": [
    "# 观察 result\n",
    "print(type(results)) #list\n",
    "print(len(results)) #len == 1\n",
    "\n",
    "# 一行一行打印结果\n",
    "for i in results[0]:\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:34:29.317552Z",
     "start_time": "2024-04-14T12:34:29.308010Z"
    }
   },
   "id": "fdfdc6e32176b00f",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[67, 1, 4], dtype=float32, place=Place(cpu), stop_gradient=True,\n",
      "       [[[0.31321961, 0.49339715, 0.04822602, 0.14515717]],\n",
      "\n",
      "        [[0.28950861, 0.62963778, 0.02746405, 0.05338954]],\n",
      "\n",
      "        [[0.28341898, 0.65020341, 0.02210444, 0.04427322]],\n",
      "\n",
      "        [[0.33188316, 0.55751503, 0.04538402, 0.06521779]],\n",
      "\n",
      "        [[0.27893397, 0.49660406, 0.03833493, 0.18612701]],\n",
      "\n",
      "        [[0.44068012, 0.50218320, 0.04073957, 0.01639713]],\n",
      "\n",
      "        [[0.26973522, 0.67326468, 0.02740863, 0.02959138]],\n",
      "\n",
      "        [[0.31708074, 0.54066736, 0.03432612, 0.10792572]],\n",
      "\n",
      "        [[0.45111209, 0.52103966, 0.02357723, 0.00427103]],\n",
      "\n",
      "        [[0.24551085, 0.53290820, 0.03558519, 0.18599580]],\n",
      "\n",
      "        [[0.46177727, 0.49636334, 0.02735403, 0.01450544]],\n",
      "\n",
      "        [[0.36189422, 0.59775835, 0.02591961, 0.01442781]],\n",
      "\n",
      "        [[0.42681456, 0.53216040, 0.02991184, 0.01111329]],\n",
      "\n",
      "        [[0.22588988, 0.59159976, 0.02159392, 0.16091645]],\n",
      "\n",
      "        [[0.30426705, 0.52796263, 0.03176577, 0.13600455]],\n",
      "\n",
      "        [[0.39693043, 0.54352146, 0.03563824, 0.02390981]],\n",
      "\n",
      "        [[0.08692227, 0.41716072, 0.00498948, 0.49092752]],\n",
      "\n",
      "        [[0.14829265, 0.48074874, 0.01399151, 0.35696712]],\n",
      "\n",
      "        [[0.27219674, 0.58287036, 0.02499938, 0.11993355]],\n",
      "\n",
      "        [[0.23336785, 0.66666889, 0.01372301, 0.08624025]],\n",
      "\n",
      "        [[0.36387247, 0.55893445, 0.02559547, 0.05159771]],\n",
      "\n",
      "        [[0.19567817, 0.51668674, 0.01936608, 0.26826897]],\n",
      "\n",
      "        [[0.18783996, 0.67611325, 0.02991228, 0.10613454]],\n",
      "\n",
      "        [[0.18216947, 0.49458519, 0.02013472, 0.30311051]],\n",
      "\n",
      "        [[0.10175870, 0.45812908, 0.00644920, 0.43366301]],\n",
      "\n",
      "        [[0.11869332, 0.43113765, 0.01060380, 0.43956515]],\n",
      "\n",
      "        [[0.23150051, 0.54241359, 0.02366329, 0.20242262]],\n",
      "\n",
      "        [[0.24335796, 0.68895513, 0.01560563, 0.05208124]],\n",
      "\n",
      "        [[0.14285243, 0.44862220, 0.01619167, 0.39233369]],\n",
      "\n",
      "        [[0.18908224, 0.54444921, 0.01291183, 0.25355667]],\n",
      "\n",
      "        [[0.26760793, 0.53240252, 0.03474229, 0.16524728]],\n",
      "\n",
      "        [[0.28989270, 0.62720335, 0.02389402, 0.05900985]],\n",
      "\n",
      "        [[0.10830249, 0.43864110, 0.00821450, 0.44484180]],\n",
      "\n",
      "        [[0.23938608, 0.65221071, 0.01447240, 0.09393070]],\n",
      "\n",
      "        [[0.00012402, 0.00557853, 0.99421036, 0.00008713]],\n",
      "\n",
      "        [[0.00000014, 0.00006606, 0.99993372, 0.00000012]],\n",
      "\n",
      "        [[0.00034671, 0.00977327, 0.98961908, 0.00026100]],\n",
      "\n",
      "        [[0.00002246, 0.00131755, 0.99865341, 0.00000651]],\n",
      "\n",
      "        [[0.00007023, 0.00469055, 0.99516857, 0.00007074]],\n",
      "\n",
      "        [[0.00000011, 0.00006451, 0.99993527, 0.00000011]],\n",
      "\n",
      "        [[0.00000017, 0.00006971, 0.99993002, 0.00000014]],\n",
      "\n",
      "        [[0.00013483, 0.00451953, 0.99527019, 0.00007542]],\n",
      "\n",
      "        [[0.00320299, 0.03531229, 0.96040100, 0.00108373]],\n",
      "\n",
      "        [[0.00013914, 0.00570613, 0.99406588, 0.00008884]],\n",
      "\n",
      "        [[0.00000074, 0.00022116, 0.99977702, 0.00000105]],\n",
      "\n",
      "        [[0.00020826, 0.00586930, 0.99384636, 0.00007610]],\n",
      "\n",
      "        [[0.00009536, 0.00339538, 0.99648005, 0.00002921]],\n",
      "\n",
      "        [[0.00006399, 0.00283855, 0.99707532, 0.00002213]],\n",
      "\n",
      "        [[0.00006426, 0.00232143, 0.99759859, 0.00001574]],\n",
      "\n",
      "        [[0.00005695, 0.00223491, 0.99769634, 0.00001175]],\n",
      "\n",
      "        [[0.00082625, 0.01327703, 0.98559952, 0.00029727]],\n",
      "\n",
      "        [[0.00000359, 0.00059611, 0.99939501, 0.00000523]],\n",
      "\n",
      "        [[0.15920019, 0.47658879, 0.01904862, 0.34516239]],\n",
      "\n",
      "        [[0.12686591, 0.46340144, 0.01117067, 0.39856201]],\n",
      "\n",
      "        [[0.09284800, 0.41793302, 0.00585699, 0.48336211]],\n",
      "\n",
      "        [[0.11550161, 0.45084476, 0.00945948, 0.42419416]],\n",
      "\n",
      "        [[0.12725177, 0.46960965, 0.01081083, 0.39232779]],\n",
      "\n",
      "        [[0.12256328, 0.46750960, 0.00933454, 0.40059257]],\n",
      "\n",
      "        [[0.11967722, 0.44051161, 0.01048465, 0.42932647]],\n",
      "\n",
      "        [[0.07641798, 0.40886727, 0.00366913, 0.51104558]],\n",
      "\n",
      "        [[0.08881795, 0.41988474, 0.00520355, 0.48609379]],\n",
      "\n",
      "        [[0.12888601, 0.46136066, 0.01151521, 0.39823815]],\n",
      "\n",
      "        [[0.11183695, 0.45350045, 0.00824369, 0.42641899]],\n",
      "\n",
      "        [[0.10409706, 0.44021299, 0.00731260, 0.44837734]],\n",
      "\n",
      "        [[0.10050988, 0.43905583, 0.00667118, 0.45376301]],\n",
      "\n",
      "        [[0.14543709, 0.47397658, 0.01371980, 0.36686650]],\n",
      "\n",
      "        [[0.10486222, 0.43609446, 0.00758324, 0.45146015]]])\n"
     ]
    }
   ],
   "source": [
    "# 将结果用 softmax 处理后变成概率值\n",
    "x = paddle.to_tensor(results[0])\n",
    "m = paddle.nn.Softmax()\n",
    "out = m(x)\n",
    "print(out)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:34:29.325553Z",
     "start_time": "2024-04-14T12:34:29.318760Z"
    }
   },
   "id": "a6235988d42b417",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#用一个字典，指名标签对应的数值\n",
    "label_dic = {}\n",
    "for i, label in enumerate(labels):\n",
    "    label_dic[i] = label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:34:29.329377Z",
     "start_time": "2024-04-14T12:34:29.326618Z"
    }
   },
   "id": "c05b151ae53b8ba7",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#预测标签结果写入predict_labels\n",
    "predict_labels = []\n",
    "#依次取results[0]中的每个图片的预测数组\n",
    "for result in results[0]: \n",
    "    #np.argmax:返回一个numpy数组中的最大值的索引\n",
    "    #注意：索引是标签，不是返回数据的最大值\n",
    "    lab_index = np.argmax(result)\n",
    "    lab = label_dic[lab_index]\n",
    "    predict_labels.append(lab)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:34:29.334816Z",
     "start_time": "2024-04-14T12:34:29.330450Z"
    }
   },
   "id": "c0e164ff67c97592",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'S3', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'S3', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'S3', 'M2', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'M2', 'M2', 'S3', 'M2', 'M2', 'M2', 'M2', 'S3', 'S3', 'M2', 'M2', 'S3', 'S3', 'M2', 'S3']\n"
     ]
    }
   ],
   "source": [
    "#看一下预测结果\n",
    "print(predict_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:34:29.339140Z",
     "start_time": "2024-04-14T12:34:29.335890Z"
    }
   },
   "id": "9215f73368026c8f",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "final_result = [ ]\n",
    "file_name_test = train_parameters['test_list_dir'] \n",
    "f = open(file_name_test, 'r') \n",
    "#按行读取数据\n",
    "data = f.readlines()\n",
    "for i in range(len(data)):\n",
    "    #将每行数据按照空格分割成2部分，并取第一部分的路径名和图像文件名，例如:R0/1.png\n",
    "    img_path = data[i].split('\\t')[0]\n",
    "    final_result.append(img_path + ',' + str(predict_labels[i]) + '\\n')\n",
    "\n",
    "f.close( )\n",
    "\n",
    "with open('result.csv',\"w\") as f: \n",
    "    f.writelines(final_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T12:34:29.345501Z",
     "start_time": "2024-04-14T12:34:29.340285Z"
    }
   },
   "id": "3bd0c8db05d7c244",
   "execution_count": 63
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

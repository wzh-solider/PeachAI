{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#os ： OS模块提供了非常丰富的方法用来处理文件和目录。\n",
    "#sys：sys模块提供了一系列有关Python运行环境的变量和函数。\n",
    "#shutil:用于文件拷贝的模块 \n",
    "#numpy：numpy 是 Python 语言的一个扩展程序库，支持大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。\n",
    "#random：Python中的random模块用于生成随机数。\n",
    "#paddle.vision.datasets：该模块包含数据加载的相关函数，比如可以用来加载常用的数据集等，如mnist。\n",
    "#paddle.vision.transforms:该模块包含对图像进行转换的函数，比如把HWC格式的图片，转变成CHW模式的输入张量。也包含飞桨框架对于图像预处理的方式，可以快速完成常见的图像预处理，如调整色调、对比度，图像大小等；\n",
    "#paddle.io.Dataset:高模块包含了飞桨框架数据加载方式，可以“一键”完成数据的批加载与异步加载。\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import paddle\n",
    "import random\n",
    "from paddle.io import Dataset, DataLoader\n",
    "from paddle.vision.datasets import DatasetFolder, ImageFolder\n",
    "from paddle.vision import transforms as T"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:19:00.786035Z",
     "start_time": "2024-04-14T18:19:00.781301Z"
    }
   },
   "id": "340e37c3d4c0e54d",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# '''\n",
    "# 参数配置：\n",
    "# 'train_data_dir'是提供的经增强后的原始训练集；\n",
    "# 'test_image_dir'是提供的原始测试集；\n",
    "# 'train_image_dir'和'eval_image_dir'是由原始训练集经拆分后生成的实际训练集和验证集\n",
    "# 'train_list_dir'和'test_list_dir'是生成的txt文件路径\n",
    "# 'saved_model' 存放训练结果的文件夹\n",
    "# '''\n",
    "train_parameters = {\n",
    "    'train_image_dir': './data/splitted_training_data/train_images',\n",
    "    'eval_image_dir': './data/splitted_training_data/eval_images',\n",
    "    'test_image_dir': './data/enhancement_data/test',\n",
    "    'train_data_dir': './data/enhancement_data/train',\n",
    "    'train_list_dir': './data/enhancement_data/train.txt',\n",
    "    'test_list_dir': './data/enhancement_data/test.txt',\n",
    "    'saved_model': './saved_model/'\n",
    "}\n",
    "\n",
    "#数据集的4个类别标签\n",
    "labels = ['R0', 'B1', 'M2', 'S3']\n",
    "labels.sort()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:19:00.822500Z",
     "start_time": "2024-04-14T18:19:00.818386Z"
    }
   },
   "id": "b4c6c18e4a0c066d",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#准备生成训练集文件名、标签名的txt文件\n",
    "write_file_name = train_parameters['train_list_dir']\n",
    "\n",
    "#以写方式打开write_file_name文件\n",
    "with open(write_file_name, \"w\") as write_file:\n",
    "    #针对不同的分类标签分别录入\n",
    "    for label in labels:\n",
    "        #建立空列表，用于保存图片名\n",
    "        file_list = []\n",
    "        #用于找到该标签路径下的所有图片.\n",
    "        train_txt_dir = train_parameters['train_data_dir'] + '/' + label + '/'\n",
    "\n",
    "        for file_name in os.listdir(train_txt_dir):\n",
    "            dir_name = label\n",
    "            temp_line = dir_name + '/' + file_name + '\\t' + label + '\\n'  # 例如：\"B1/101.png\tB1\"\n",
    "            write_file.write(temp_line)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:19:00.848095Z",
     "start_time": "2024-04-14T18:19:00.836391Z"
    }
   },
   "id": "7a22f6855f6393e6",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#准备生成测试集文件名、标签名的txt文件\n",
    "write_file_name = train_parameters['test_list_dir']\n",
    "\n",
    "#以写方式打开write_file_name文件\n",
    "with open(write_file_name, \"w\") as write_file:\n",
    "    #针对不同的分类标签分别录入\n",
    "    for label in labels:\n",
    "        #建立空列表，用于保存图片名\n",
    "        file_list = []\n",
    "        #用于找到该标签路径下的所有图片.\n",
    "        train_txt_dir = train_parameters['test_image_dir'] + '/' + label + '/'\n",
    "\n",
    "        for file_name in os.listdir(train_txt_dir):\n",
    "            dir_name = label\n",
    "            temp_line = dir_name + '/' + file_name + '\\t' + label + '\\n'  # 例如：\"B1/101.png\tB1\"\n",
    "            write_file.write(temp_line)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:19:00.854925Z",
     "start_time": "2024-04-14T18:19:00.849158Z"
    }
   },
   "id": "824e3679d30e2822",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#判断splitted_training_data文件夹是否存在，如果不存在就新建一个\n",
    "if not os.path.exists('data/splitted_training_data'):\n",
    "    os.makedirs('data/splitted_training_data')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:19:00.859123Z",
     "start_time": "2024-04-14T18:19:00.856052Z"
    }
   },
   "id": "4ae867d3577c06b4",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating training and eval images\n",
      "划分训练集和验证集完成！\n"
     ]
    }
   ],
   "source": [
    "#定义一个函数，来拆分训练集、验证集\n",
    "def create_train_eval():\n",
    "    '''\n",
    "    划分训练集和验证集\n",
    "    '''\n",
    "    train_dir = train_parameters['train_image_dir']\n",
    "    eval_dir = train_parameters['eval_image_dir']\n",
    "    train_list_path = train_parameters['train_list_dir']\n",
    "    train_data_dir = train_parameters['train_data_dir']\n",
    "\n",
    "    print('creating training and eval images')\n",
    "    #如果文件夹不存在，建立相应的文件夹\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.mkdir(train_dir)\n",
    "    if not os.path.exists(eval_dir):\n",
    "        os.mkdir(eval_dir)\n",
    "\n",
    "        #打开txt文件，分割数据\n",
    "    file_name = train_list_path\n",
    "    f = open(file_name, 'r')\n",
    "    #按行读取数据\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        #将每行数据按照空格分割成2部分，并取第一部分的路径名和图像文件名，例如:R0/1.png\n",
    "        img_path = lines[i].split('\\t')[0]\n",
    "        #取第二部分的标签，例如:R0\n",
    "        class_label = lines[i].split('\\t')[1].strip('\\n')\n",
    "        # 每8张图片取一个做验证数据,其他用于训练\n",
    "        if i % 8 == 0:\n",
    "            #把目录和文件名合成一个路径\n",
    "            eval_target_dir = os.path.join(eval_dir, class_label)\n",
    "            #将总的文件路径与当前图像的文件名合到一起，实际就是得到训练集图像所在的文件夹下的图像名   \n",
    "            eval_img_path = os.path.join(train_data_dir, img_path)\n",
    "            if not os.path.exists(eval_target_dir):\n",
    "                os.mkdir(eval_target_dir)\n",
    "                #将图片复制到验证集指定标签的文件夹下      \n",
    "            shutil.copy(eval_img_path, eval_target_dir)\n",
    "        else:\n",
    "            train_target_dir = os.path.join(train_dir, class_label)\n",
    "            train_img_path = os.path.join(train_data_dir, img_path)\n",
    "            if not os.path.exists(train_target_dir):\n",
    "                os.mkdir(train_target_dir)\n",
    "            shutil.copy(train_img_path, train_target_dir)\n",
    "    print('划分训练集和验证集完成！')\n",
    "\n",
    "# 制作数据集，如果已经做好了，就请将代码注释掉\n",
    "# create_train_eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:19:11.286452Z",
     "start_time": "2024-04-14T18:19:00.865591Z"
    }
   },
   "id": "7322e039ad424623",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class PeachDataset(Dataset):\n",
    "    \"\"\"\n",
    "    步骤一：继承paddle.io.Dataset类\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mode='train'):\n",
    "        \"\"\"\n",
    "        步骤二：实现构造函数，定义数据读取方式，划分训练、验证和测试数据集\n",
    "        \"\"\"\n",
    "        super(PeachDataset, self).__init__()\n",
    "        train_image_dir = train_parameters['train_image_dir']  #训练集的路径\n",
    "        eval_image_dir = train_parameters['eval_image_dir']\n",
    "        test_image_dir = train_parameters['test_image_dir']\n",
    "\n",
    "        '''         '''\n",
    "        #transform数据增强函数，这里仅对图片的打开方式进行了转换            \n",
    "        #这里用Transpose()将图片的打开方式(宽, 高, 通道数)更改为PaddlePaddle读取的方式是(通道数, 宽, 高)\n",
    "        mean = [127.5, 127.5, 127.5]  # 归一化，均值\n",
    "        std = [127.5, 127.5, 127.5]  # 归一化，标注差 \n",
    "        transform_train = T.Compose([T.ColorJitter(0.4, 0.4, 0.4, 0.4)\n",
    "                                        , T.Resize(size=(224, 224))\n",
    "                                        , T.Transpose()\n",
    "                                        , T.Normalize(mean, std)\n",
    "                                     ])\n",
    "        transform_eval = T.Compose([T.Resize(size=(224, 224))\n",
    "                                       , T.Transpose()\n",
    "                                       , T.Normalize(mean, std)\n",
    "                                    ])\n",
    "        transform_test = T.Compose([T.Resize(size=(224, 224))\n",
    "                                       , T.Transpose()\n",
    "                                       , T.Normalize(mean, std)\n",
    "                                    ])\n",
    "\n",
    "        '''         \n",
    "        # 参考API：https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/Overview_cn.html#about-transforms\n",
    "        #这里用Transpose()将图片的打开方式(宽, 高, 通道数)更改为PaddlePaddle读取的方式是(通道数, 宽, 高)\n",
    "        # ColorJitter 随机调整图像的亮度，对比度，饱和度和色调。\n",
    "        # hflip 对输入图像进行水平翻转。        \n",
    "        # Normalize 归一化。mean = [127.5, 127.5, 127.5]，std = [127.5, 127.5, 127.5]\n",
    "        # RandomHorizontalFlip 基于概率来执行图片的水平翻转。\n",
    "        # RandomVerticalFlip 基于概率来执行图片的垂直翻转。\n",
    "        mean = [127.5, 127.5, 127.5] # 归一化，均值\n",
    "        std = [127.5, 127.5, 127.5] # 归一化，标注差 \n",
    "        transform_train = T.Compose([T.Resize(size=(224,224)), \n",
    "                                     T.Transpose(),                                \n",
    "                                     T.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "                                     T.RandomHorizontalFlip(prob=0.5,),\n",
    "                                     T.RandomVerticalFlip(prob=0.5,),\n",
    "                                     T.Normalize(mean, std)])\n",
    "        transform_eval = T.Compose([T.Resize(size=(224,224)), T.Transpose()])\n",
    "        transform_test = T.Compose([T.Resize(size=(224,224)), T.Transpose()])\n",
    "        '''\n",
    "\n",
    "        #飞桨推荐使用 paddle.io.DataLoader 完成数据的加载，生成一个可以加载数据的迭代器\n",
    "        # 参考API:https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/io/DataLoader_cn.html#cn-api-fluid-io-dataloader\n",
    "        #加载训练集，train_data_folder 是一个迭代器\n",
    "        # 参考API：https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/datasets/DatasetFolder_cn.html#datasetfolder\n",
    "        train_data_folder = DatasetFolder(train_image_dir, transform=transform_train)\n",
    "        #加载验证集，eval_data_folder 是一个迭代器\n",
    "        eval_data_folder = DatasetFolder(eval_image_dir, transform=transform_eval)\n",
    "        #加载测试集，test_data_folder 是一个迭代器\n",
    "        test_data_folder = DatasetFolder(test_image_dir, transform=transform_test)\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "            self.data = train_data_folder\n",
    "        elif self.mode == 'eval':\n",
    "            self.data = eval_data_folder\n",
    "        elif self.mode == 'test':\n",
    "            self.data = test_data_folder\n",
    "\n",
    "    # 每次迭代时返回数据和对应的标签\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        步骤三：实现__getitem__方法，定义指定index时如何获取数据，并返回单条数据（训练数据，对应的标签）\n",
    "        \"\"\"\n",
    "        data = np.array(self.data[index][0]).astype('float32')\n",
    "\n",
    "        label = np.array([self.data[index][1]]).astype('int64')\n",
    "\n",
    "        return data, label\n",
    "\n",
    "    # 返回整个数据集的总数\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        步骤四：实现__len__方法，返回数据集总数目\n",
    "        \"\"\"\n",
    "        return len(self.data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:19:11.294313Z",
     "start_time": "2024-04-14T18:19:11.287602Z"
    }
   },
   "id": "c458ab62832e2857",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#用自定义的PeachDataset类，加载自己的数据集\n",
    "train_dataset = PeachDataset(mode='train')\n",
    "val_dataset = PeachDataset(mode='eval')\n",
    "test_dataset = PeachDataset(mode='test')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:19:11.432838Z",
     "start_time": "2024-04-14T18:19:11.295349Z"
    }
   },
   "id": "8276f74e1dd0f1b8",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opencv 版本号为：4.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\io\\reader.py:429: UserWarning: DataLoader with multi-process mode is not supported on MacOs and Windows currently. Please use signle-process mode with num_workers = 0 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# DataLoader 示例代码\n",
    "\n",
    "# 加载库\n",
    "import cv2 as cv  #使用 OpenCV\n",
    "\n",
    "print(\"opencv 版本号为：\" + cv.__version__)  #查看版本号\n",
    "# 事实上在使用 OpenCV之前应该安装该类库，但是由于使用了 AI-Studio，所以系统已经替开发者预先安装好了： opencv-python 4.1.1.26       \n",
    "from matplotlib import pyplot as plt  #在该页面画图\n",
    "%matplotlib inline \n",
    "\n",
    "# 构造一个 DataLoader\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=2,\n",
    "                         shuffle=True,\n",
    "                         drop_last=True,\n",
    "                         num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:19:11.773374Z",
     "start_time": "2024-04-14T18:19:11.433840Z"
    }
   },
   "id": "37945b6eb1cae757",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini_batch 的类型为：<class 'list'>\n",
      "mini_batch 的大小为：2\n",
      "(3, 224, 224)\n",
      "(3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "# 使用 DataLoader 来遍历数据集\n",
    "for mini_batch in test_loader:  # 从 DataLoader 中获取 mini_batch \n",
    "    print(\"mini_batch 的类型为：\" + str(type(mini_batch)))\n",
    "    pic_list = mini_batch[0]  #图片数据\n",
    "    label_list = mini_batch[1]  #标记\n",
    "    print(\"mini_batch 的大小为：\" + str(len(pic_list)))\n",
    "\n",
    "    # 将图片显示转化为 numpy 格式，并且将内部的数字设置为 整数类型\n",
    "    pic_1 = pic_list[0]\n",
    "    pic_2 = pic_list[1]\n",
    "    arr1 = np.asarray(pic_1, dtype=np.float64)\n",
    "    print(arr1.shape)\n",
    "    arr2 = np.asarray(pic_2, dtype=np.float64)\n",
    "    print(arr2.shape)\n",
    "\n",
    "    break  #由于是示例，所以仅拿出第一个 mini_batch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:19:11.805347Z",
     "start_time": "2024-04-14T18:19:11.774379Z"
    }
   },
   "id": "75353e4e8724dc25",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 把获取到的图片数据展示出来\n",
    "# arr1 = arr1 / 255 # 把每一个像素都变到 0-1 之间\n",
    "# r = arr1[0]\n",
    "# g = arr1[1]\n",
    "# b = arr1[2]\n",
    "# img = cv.merge([r, g, b])\n",
    "# \n",
    "# plt.imshow(img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:19:11.809962Z",
     "start_time": "2024-04-14T18:19:11.806417Z"
    }
   },
   "id": "95ae01f36911f7db",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:2084: UserWarning: Skip loading for fc.weight. fc.weight receives a shape [512, 1000], but the expected shape is [512, 4].\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "E:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:2084: UserWarning: Skip loading for fc.bias. fc.bias receives a shape [1000], but the expected shape is [4].\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n"
     ]
    }
   ],
   "source": [
    "# 使用内置的模型,这边可以选择多种不同网络，这里选了resnet50网络\n",
    "#pretrained (bool，可选) - 是否加载在imagenet数据集上的预训练权重\n",
    "model = paddle.vision.models.resnet18(pretrained=True, num_classes=4)\n",
    "\n",
    "#尝试不同的网络结构：MobileNetV2\n",
    "# MobileNetV2参考文档：https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/models/MobileNetV2_cn.html\n",
    "# model = paddle.vision.models.mobilenet_v2(pretrained=True, num_classes=4)    \n",
    "\n",
    "#使用paddle.Model完成模型的封装，将网络结构组合成一个可快速使用高层API进行训练和预测的类。\n",
    "model = paddle.Model(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:19:12.765114Z",
     "start_time": "2024-04-14T18:19:11.812199Z"
    }
   },
   "id": "1e273f2031247d08",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "   Layer (type)         Input Shape          Output Shape         Param #    \n",
      "===============================================================================\n",
      "     Conv2D-1        [[1, 3, 224, 224]]   [1, 64, 112, 112]        9,408     \n",
      "   BatchNorm2D-1    [[1, 64, 112, 112]]   [1, 64, 112, 112]         256      \n",
      "      ReLU-1        [[1, 64, 112, 112]]   [1, 64, 112, 112]          0       \n",
      "    MaxPool2D-1     [[1, 64, 112, 112]]    [1, 64, 56, 56]           0       \n",
      "     Conv2D-2        [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \n",
      "   BatchNorm2D-2     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \n",
      "      ReLU-2         [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "     Conv2D-3        [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \n",
      "   BatchNorm2D-3     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \n",
      "   BasicBlock-1      [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "     Conv2D-4        [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \n",
      "   BatchNorm2D-4     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \n",
      "      ReLU-3         [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "     Conv2D-5        [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \n",
      "   BatchNorm2D-5     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \n",
      "   BasicBlock-2      [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "     Conv2D-7        [[1, 64, 56, 56]]     [1, 128, 28, 28]       73,728     \n",
      "   BatchNorm2D-7     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "      ReLU-4         [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "     Conv2D-8        [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456    \n",
      "   BatchNorm2D-8     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "     Conv2D-6        [[1, 64, 56, 56]]     [1, 128, 28, 28]        8,192     \n",
      "   BatchNorm2D-6     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "   BasicBlock-3      [[1, 64, 56, 56]]     [1, 128, 28, 28]          0       \n",
      "     Conv2D-9        [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456    \n",
      "   BatchNorm2D-9     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "      ReLU-5         [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "     Conv2D-10       [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456    \n",
      "  BatchNorm2D-10     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "   BasicBlock-4      [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "     Conv2D-12       [[1, 128, 28, 28]]    [1, 256, 14, 14]       294,912    \n",
      "  BatchNorm2D-12     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "      ReLU-6         [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \n",
      "     Conv2D-13       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \n",
      "  BatchNorm2D-13     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "     Conv2D-11       [[1, 128, 28, 28]]    [1, 256, 14, 14]       32,768     \n",
      "  BatchNorm2D-11     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "   BasicBlock-5      [[1, 128, 28, 28]]    [1, 256, 14, 14]          0       \n",
      "     Conv2D-14       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \n",
      "  BatchNorm2D-14     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "      ReLU-7         [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \n",
      "     Conv2D-15       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \n",
      "  BatchNorm2D-15     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "   BasicBlock-6      [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \n",
      "     Conv2D-17       [[1, 256, 14, 14]]     [1, 512, 7, 7]       1,179,648   \n",
      "  BatchNorm2D-17      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "      ReLU-8          [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "     Conv2D-18        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296   \n",
      "  BatchNorm2D-18      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "     Conv2D-16       [[1, 256, 14, 14]]     [1, 512, 7, 7]        131,072    \n",
      "  BatchNorm2D-16      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "   BasicBlock-7      [[1, 256, 14, 14]]     [1, 512, 7, 7]           0       \n",
      "     Conv2D-19        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296   \n",
      "  BatchNorm2D-19      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "      ReLU-9          [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "     Conv2D-20        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296   \n",
      "  BatchNorm2D-20      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "   BasicBlock-8       [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "AdaptiveAvgPool2D-1   [[1, 512, 7, 7]]      [1, 512, 1, 1]           0       \n",
      "     Linear-1            [[1, 512]]             [1, 4]             2,052     \n",
      "===============================================================================\n",
      "Total params: 11,188,164\n",
      "Trainable params: 11,178,564\n",
      "Non-trainable params: 9,600\n",
      "-------------------------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 57.04\n",
      "Params size (MB): 42.68\n",
      "Estimated Total Size (MB): 100.30\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'total_params': 11188164, 'trainable_params': 11178564}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 summary 观察网络信息\n",
    "model.summary(input_size=(1, 3, 224, 224), dtype='float32')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:19:12.864836Z",
     "start_time": "2024-04-14T18:19:12.766057Z"
    }
   },
   "id": "447241548baab581",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8ba14f87476e42c9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 调用Paddle的VisualDL模块，保存信息到目录中。\n",
    "#log_dir (str) - 输出日志保存的路径。\n",
    "callback = paddle.callbacks.VisualDL(log_dir='visualdl_log_dir')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:19:12.868274Z",
     "start_time": "2024-04-14T18:19:12.864836Z"
    }
   },
   "id": "909a9fae18ee48f8",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#通过Model.prepare接口来对训练进行提前的配置准备工作，包括设置模型优化器，Loss计算方法，精度计算方法等\n",
    "# 优化器API文档： https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/optimizer/Overview_cn.html#paddle-optimizer\n",
    "\n",
    "# 学习率衰减策略\n",
    "# 学习率衰减策略 API 文档：https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/optimizer/Overview_cn.html#about-lr\n",
    "scheduler_StepDecay = paddle.optimizer.lr.StepDecay(learning_rate=0.1, step_size=50, gamma=0.9, verbose=False)\n",
    "scheduler_PiecewiseDecay = paddle.optimizer.lr.PiecewiseDecay(boundaries=[100, 1000, 4000, 5000, 6000],\n",
    "                                                              values=[0.1, 0.5, 0.01, 0.005, 0.001, 0.0005],\n",
    "                                                              verbose=False)\n",
    "\n",
    "# 尝试使用 SGD、Momentum 方法\n",
    "sgd = paddle.optimizer.SGD(\n",
    "    learning_rate=scheduler_StepDecay,\n",
    "    parameters=model.parameters())\n",
    "\n",
    "adam = paddle.optimizer.Adam(\n",
    "    learning_rate=0.01,  #调参\n",
    "    parameters=model.parameters())\n",
    "\n",
    "model.prepare(optimizer=adam,  # adam\n",
    "              loss=paddle.nn.CrossEntropyLoss(),\n",
    "              metrics=paddle.metric.Accuracy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:19:12.875920Z",
     "start_time": "2024-04-14T18:19:12.870426Z"
    }
   },
   "id": "747a69731cf6ebc8",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Place(cpu)\n"
     ]
    }
   ],
   "source": [
    "# 查看当前计算设备\n",
    "device = paddle.device.get_device()\n",
    "print(device)\n",
    "# 使用CPU训练\n",
    "device = paddle.set_device('cpu')  # or 'cpu'\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:19:12.880527Z",
     "start_time": "2024-04-14T18:19:12.876462Z"
    }
   },
   "id": "51f695f8d10b1088",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\code\\python\\PeachAI\\.venv\\Lib\\site-packages\\paddle\\nn\\layer\\norm.py:824: UserWarning: When training, we now always track global mean and variance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2904/2904 [==============================] - loss: 1.0771 - acc: 0.2960 - 801ms/step          \n",
      "Eval begin...\n",
      "step 415/415 [==============================] - loss: 1.4707 - acc: 0.2060 - 122ms/step          \n",
      "Eval samples: 830\n"
     ]
    }
   ],
   "source": [
    "# fit API文档： https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/Model_cn.html#fit-train-data-none-eval-data-none- -size-1-epochs-1-eval-freq-1-log-freq-10-save-dir-none-save-freq-1-verbose-2-drop-last-false-shuffle-true-num-workers-0-callbacks-none\n",
    "\n",
    "# 启动模型训练，指定训练数据集，设置训练轮次，设置每次数据集计算的批次大小，设置日志格式\n",
    "#epochs：总共训练的轮数\n",
    "#batch_size：一个批次的样本数量\n",
    "#如果提示内存不足，可以尝试将batch_size调低\n",
    "#verbose：日志显示，0为不在标准输出流输出日志信息,1为输出进度条记录，2为每个epoch输出一行记录;1为输出进度条记录，2为每个epoch输出一行记录\n",
    "\n",
    "model.fit(train_dataset,\n",
    "          val_dataset,\n",
    "          epochs=1,\n",
    "          batch_size=2,\n",
    "          callbacks=callback,\n",
    "          verbose=1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:58:48.998619Z",
     "start_time": "2024-04-14T18:19:12.881615Z"
    }
   },
   "id": "2e1ddae510334aca",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "step 67/67 [==============================] - loss: 1.5000 - acc: 0.2388 - 68ms/step          \n",
      "Eval samples: 67\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'loss': [1.4999852180480957], 'acc': 0.23880597014925373}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#模型评估\n",
    "#对于训练好的模型进行评估操作可以使用 model.evaluate 接口；操作结束后会根据 prepare 接口配置的 loss 和 metric 来进行相关指标计算返回。\n",
    "# 评价指标参考文档：https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/Model_cn.html#evaluate-eval-data-batch-size-1-log-freq-10-verbose-2-num-workers-0-callbacks-none\n",
    "model.evaluate(test_dataset, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:58:53.537595Z",
     "start_time": "2024-04-14T18:58:48.999625Z"
    }
   },
   "id": "59315ed2fdf29ad3",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#模型保存\n",
    "model.save('./saved_model/saved_model')  # save for training"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:58:53.717968Z",
     "start_time": "2024-04-14T18:58:53.538732Z"
    }
   },
   "id": "dcb089a314a16a3f",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict begin...\n",
      "step 67/67 [==============================] - 69ms/step          \n",
      "Predict samples: 67\n"
     ]
    }
   ],
   "source": [
    "#预测模型\n",
    "results = model.predict(test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:58:58.335638Z",
     "start_time": "2024-04-14T18:58:53.718974Z"
    }
   },
   "id": "6ff51e8f188047ac",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "1\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.01577358  0.02951426  0.0942404  -0.10050384]]\n",
      "[[-0.04913574  0.08588447  0.00905911 -0.05308082]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.03118148  0.05855016  0.04736123 -0.07845654]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.06127474  0.10143872 -0.01863645 -0.03898186]]\n",
      "[[-0.01004713  0.01669553  0.11989272 -0.11144774]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.02723762  0.04724887  0.06973968 -0.08651312]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.06256416  0.10952044 -0.03800415 -0.0346028 ]]\n",
      "[[-0.03215452  0.05910802  0.05344851 -0.07791075]]\n",
      "[[ 0.50886524  0.46928394  0.1515083  -1.2053964 ]]\n",
      "[[-0.01013583  0.01890276  0.11582739 -0.1100823 ]]\n",
      "[[-0.01097055  0.01812863  0.11635602 -0.10965054]]\n",
      "[[ 0.10846568  0.3877498  -0.13738427 -0.42632028]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.04772535  0.08740329  0.00139598 -0.05317223]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.03569597  0.06226373  0.04140898 -0.07353826]]\n",
      "[[-0.09060313  0.15941398 -0.10714671  0.00504027]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.28303462  0.48901394 -0.52428967  0.24704903]]\n",
      "[[-0.00987852  0.0163729   0.12073091 -0.1117681 ]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.02388106  0.04799952  0.06543884 -0.0864886 ]]\n",
      "[[-0.063012    0.10223331 -0.01821937 -0.03689895]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[ 0.7120563   0.48836622  0.29012945 -1.5908014 ]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[ 0.34918055  0.58252096 -0.12139916 -0.93572056]]\n",
      "[[-0.01579507  0.02734294  0.09865549 -0.1013034 ]]\n",
      "[[ 1.0659705   0.7636339   0.28343913 -2.3195846 ]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[ 0.60508883  0.49817085  0.19217746 -1.3892438 ]]\n",
      "[[-0.04429443  0.07698286  0.01519939 -0.05924781]]\n",
      "[[ 0.47650316  0.39888307  0.18863183 -1.14734   ]]\n",
      "[[-0.06356879  0.10776503 -0.02212374 -0.04168972]]\n",
      "[[-0.02593859  0.04529179  0.06888078 -0.08825632]]\n",
      "[[-0.01806649  0.03287681  0.09144255 -0.09839309]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.02066578  0.03361886  0.08826171 -0.09613927]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.12395075  0.20884189 -0.20426565  0.05431173]]\n",
      "[[ 0.5319263   0.57492185  0.05880317 -1.3079647 ]]\n",
      "[[-0.53588134  0.9068947  -1.0387368   0.56962556]]\n",
      "[[-0.27475566  0.4590887  -0.4987144   0.2436327 ]]\n",
      "[[-0.19530869  0.33294427 -0.32124075  0.13779446]]\n",
      "[[-0.12334246  0.20413755 -0.16823462  0.04624637]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.05081363  0.08713386 -0.00274251 -0.05044665]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.14296275  0.24268721 -0.22857517  0.07570948]]\n",
      "[[-0.43463948  0.72195095 -0.8221555   0.44117606]]\n",
      "[[-0.31349745  0.5411034  -0.5719296   0.28411266]]\n",
      "[[-0.00916194  0.01554003  0.12297988 -0.11300992]]\n",
      "[[-0.8138804   1.3903362  -1.6279345   0.91666114]]\n",
      "[[-0.04621353  0.07879093  0.01179221 -0.05736028]]\n",
      "[[-0.01299505  0.02149305  0.11169037 -0.10743042]]\n"
     ]
    }
   ],
   "source": [
    "# 观察 result\n",
    "print(type(results))  #list\n",
    "print(len(results))  #len == 1\n",
    "\n",
    "# 一行一行打印结果\n",
    "for i in results[0]:\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:58:58.345525Z",
     "start_time": "2024-04-14T18:58:58.336866Z"
    }
   },
   "id": "fdfdc6e32176b00f",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[67, 1, 4], dtype=float32, place=Place(cpu), stop_gradient=True,\n",
      "       [[[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.24501501, 0.25636628, 0.27350870, 0.22511001]],\n",
      "\n",
      "        [[0.23806439, 0.27247897, 0.25232956, 0.23712707]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.24216501, 0.26489964, 0.26195222, 0.23098305]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.23569325, 0.27734011, 0.24596012, 0.24100652]],\n",
      "\n",
      "        [[0.24573438, 0.25239462, 0.27983245, 0.22203846]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.24262345, 0.26138571, 0.26733109, 0.22865976]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.23579353, 0.28007045, 0.24165632, 0.24247970]],\n",
      "\n",
      "        [[0.24153391, 0.26461408, 0.26312071, 0.23073126]],\n",
      "\n",
      "        [[0.35201213, 0.33835119, 0.24624051, 0.06339620]],\n",
      "\n",
      "        [[0.24578536, 0.25302726, 0.27877969, 0.22240770]],\n",
      "\n",
      "        [[0.24561894, 0.25287125, 0.27897102, 0.22253877]],\n",
      "\n",
      "        [[0.27100146, 0.35831350, 0.21193385, 0.15875120]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.23868626, 0.27322036, 0.25070360, 0.23738971]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.24119993, 0.26602381, 0.26053339, 0.23224290]],\n",
      "\n",
      "        [[0.22893737, 0.29396644, 0.22518109, 0.25191504]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.17702529, 0.38311729, 0.13907836, 0.30077913]],\n",
      "\n",
      "        [[0.24574548, 0.25228208, 0.28003255, 0.22193995]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.24347076, 0.26161590, 0.26621833, 0.22869503]],\n",
      "\n",
      "        [[0.23518619, 0.27744502, 0.24596028, 0.24140851]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.39134079, 0.31290159, 0.25663427, 0.03912342]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.31604269, 0.39910227, 0.19741292, 0.08744204]],\n",
      "\n",
      "        [[0.24489486, 0.25569031, 0.27459013, 0.22482462]],\n",
      "\n",
      "        [[0.44839129, 0.33140117, 0.20502561, 0.01518201]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.37086147, 0.33325589, 0.24540679, 0.05047590]],\n",
      "\n",
      "        [[0.23949830, 0.27037871, 0.25417936, 0.23594363]],\n",
      "\n",
      "        [[0.34815142, 0.32215005, 0.26106414, 0.06863443]],\n",
      "\n",
      "        [[0.23522088, 0.27918059, 0.24517445, 0.24042401]],\n",
      "\n",
      "        [[0.24313903, 0.26108965, 0.26732171, 0.22844963]],\n",
      "\n",
      "        [[0.24445046, 0.25722623, 0.27274075, 0.22558254]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.24401131, 0.25762349, 0.27209249, 0.22627273]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.22159079, 0.30908769, 0.20448968, 0.26483178]],\n",
      "\n",
      "        [[0.35387939, 0.36942649, 0.22048576, 0.05620835]],\n",
      "\n",
      "        [[0.11289250, 0.47780946, 0.06827752, 0.34102061]],\n",
      "\n",
      "        [[0.17979982, 0.37453625, 0.14372265, 0.30194128]],\n",
      "\n",
      "        [[0.20108859, 0.34103957, 0.17729473, 0.28057715]],\n",
      "\n",
      "        [[0.22082926, 0.30639338, 0.21113500, 0.26164240]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.23823546, 0.27347413, 0.24996744, 0.23832291]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.21584554, 0.31741592, 0.19813539, 0.26860321]],\n",
      "\n",
      "        [[0.13776667, 0.43797070, 0.09350786, 0.33075473]],\n",
      "\n",
      "        [[0.16833693, 0.39566520, 0.13000011, 0.30599770]],\n",
      "\n",
      "        [[0.24584265, 0.25199109, 0.28057289, 0.22159331]],\n",
      "\n",
      "        [[0.06191983, 0.56118858, 0.02743409, 0.34945750]],\n",
      "\n",
      "        [[0.23913205, 0.27097332, 0.25341329, 0.23648131]],\n",
      "\n",
      "        [[0.24523218, 0.25383732, 0.27779707, 0.22313346]]])\n"
     ]
    }
   ],
   "source": [
    "# 将结果用 softmax 处理后变成概率值\n",
    "x = paddle.to_tensor(results[0])\n",
    "m = paddle.nn.Softmax()\n",
    "out = m(x)\n",
    "print(out)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:58:58.352574Z",
     "start_time": "2024-04-14T18:58:58.346593Z"
    }
   },
   "id": "a6235988d42b417",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#用一个字典，指名标签对应的数值\n",
    "label_dic = {}\n",
    "for i, label in enumerate(labels):\n",
    "    label_dic[i] = label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:58:58.356862Z",
     "start_time": "2024-04-14T18:58:58.353632Z"
    }
   },
   "id": "c05b151ae53b8ba7",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#预测标签结果写入predict_labels\n",
    "predict_labels = []\n",
    "#依次取results[0]中的每个图片的预测数组\n",
    "for result in results[0]:\n",
    "    #np.argmax:返回一个numpy数组中的最大值的索引\n",
    "    #注意：索引是标签，不是返回数据的最大值\n",
    "    lab_index = np.argmax(result)\n",
    "    lab = label_dic[lab_index]\n",
    "    predict_labels.append(lab)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:58:58.361974Z",
     "start_time": "2024-04-14T18:58:58.357939Z"
    }
   },
   "id": "c0e164ff67c97592",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R0', 'R0', 'M2', 'R0', 'M2', 'R0', 'M2', 'R0', 'R0', 'R0', 'R0', 'M2', 'M2', 'B1', 'R0', 'R0', 'M2', 'R0', 'R0', 'M2', 'R0', 'R0', 'R0', 'R0', 'M2', 'M2', 'R0', 'R0', 'M2', 'R0', 'R0', 'R0', 'M2', 'R0', 'B1', 'R0', 'M2', 'R0', 'B1', 'R0', 'B1', 'M2', 'B1', 'M2', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'R0', 'R0', 'M2', 'R0', 'M2', 'M2', 'M2', 'R0', 'M2', 'M2', 'R0']\n"
     ]
    }
   ],
   "source": [
    "#看一下预测结果\n",
    "print(predict_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:58:58.365940Z",
     "start_time": "2024-04-14T18:58:58.363041Z"
    }
   },
   "id": "9215f73368026c8f",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "final_result = []\n",
    "file_name_test = train_parameters['test_list_dir']\n",
    "f = open(file_name_test, 'r')\n",
    "#按行读取数据\n",
    "data = f.readlines()\n",
    "for i in range(len(data)):\n",
    "    #将每行数据按照空格分割成2部分，并取第一部分的路径名和图像文件名，例如:R0/1.png\n",
    "    img_path = data[i].split('\\t')[0]\n",
    "    final_result.append(img_path + ',' + str(predict_labels[i]) + '\\n')\n",
    "\n",
    "f.close()\n",
    "\n",
    "with open('result.csv', \"w\") as f:\n",
    "    f.writelines(final_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:58:58.371940Z",
     "start_time": "2024-04-14T18:58:58.367030Z"
    }
   },
   "id": "3bd0c8db05d7c244",
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
